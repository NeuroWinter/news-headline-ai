{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spacy-transfomers-practice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeuroWinter/news-headline-ai/blob/master/Spacy_transfomers_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOucPcydcmNO",
        "colab_type": "code",
        "outputId": "82515a5b-a31a-4ac2-bf7d-75549efea99d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install -U spacy[cuda100]\n",
        "!pip install spacy-transformers\n",
        "!python3 -m spacy download en_trf_distilbertbaseuncased_lg\n",
        "!pip install torch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacy[cuda100]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/13/80ad28ef7a16e2a86d16d73e28588be5f1085afd3e85e4b9b912bd700e8a/spacy-2.2.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (1.17.5)\n",
            "Collecting thinc<7.4.0,>=7.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/59/6bb553bc9a5f072d3cd479fc939fea0f6f682892f1f5cff98de5c9b615bb/thinc-7.3.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 27.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (1.0.2)\n",
            "Collecting catalogue<1.1.0,>=0.0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6c/f9/9a5658e2f56932e41eb264941f9a2cb7f3ce41a80cb36b2af6ab78e2f8af/catalogue-1.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (0.9.6)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (42.0.2)\n",
            "Collecting blis<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/19/f95c75562d18eb27219df3a3590b911e78d131b68466ad79fdf5847eaac4/blis-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 36.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (2.21.0)\n",
            "Collecting preshed<3.1.0,>=3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/6b/e07fad36913879757c90ba03d6fb7f406f7279e11dcefc105ee562de63ea/preshed-3.0.2-cp36-cp36m-manylinux1_x86_64.whl (119kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 43.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (2.0.3)\n",
            "Collecting cupy-cuda100>=5.0.0b4; extra == \"cuda100\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/3a/bf66277c1230a9cf3c26afa5b5fabc9fceb2e63f914cf5f4d59d574ac968/cupy_cuda100-7.0.0-cp36-cp36m-manylinux1_x86_64.whl (382.9MB)\n",
            "\u001b[K     |████████████████████████████████| 382.9MB 36kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.4.0,>=7.3.0->spacy[cuda100]) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy[cuda100]) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda100]) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda100]) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda100]) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda100]) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100>=5.0.0b4; extra == \"cuda100\"->spacy[cuda100]) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: fastrlock>=0.3 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100>=5.0.0b4; extra == \"cuda100\"->spacy[cuda100]) (0.4)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy[cuda100]) (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: more-itertools in /usr/local/lib/python3.6/dist-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy[cuda100]) (8.0.2)\n",
            "Installing collected packages: blis, preshed, thinc, catalogue, cupy-cuda100, spacy\n",
            "  Found existing installation: blis 0.2.4\n",
            "    Uninstalling blis-0.2.4:\n",
            "      Successfully uninstalled blis-0.2.4\n",
            "  Found existing installation: preshed 2.0.1\n",
            "    Uninstalling preshed-2.0.1:\n",
            "      Successfully uninstalled preshed-2.0.1\n",
            "  Found existing installation: thinc 7.0.8\n",
            "    Uninstalling thinc-7.0.8:\n",
            "      Successfully uninstalled thinc-7.0.8\n",
            "  Found existing installation: spacy 2.1.9\n",
            "    Uninstalling spacy-2.1.9:\n",
            "      Successfully uninstalled spacy-2.1.9\n",
            "Successfully installed blis-0.4.1 catalogue-1.0.0 cupy-cuda100-7.0.0 preshed-3.0.2 spacy-2.2.3 thinc-7.3.1\n",
            "Collecting spacy-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/fb/5dbcf7391d6ba0003fb922737340bff5033729f9c967f08f0468259c4f6a/spacy-transformers-0.5.1.tar.gz (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<2.3.0,>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from spacy-transformers) (2.2.3)\n",
            "Collecting transformers<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/99/ca0e4c35ccde7d290de3c9c236d5629d1879b04927e5ace9bd6d9183e236/transformers-2.0.0-py3-none-any.whl (290kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy-transformers) (1.3.1)\n",
            "Collecting torchcontrib<0.1.0,>=0.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/72/36/45d475035ab35353911e72a03c1c1210eba63b71e5a6917a9e78a046aa10/torchcontrib-0.0.2.tar.gz\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy-transformers) (1.0.1)\n",
            "Collecting ftfy<6.0.0,>=5.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ca/2d9a5030eaf1bcd925dab392762b9709a7ad4bd486a90599d93cd79cb188/ftfy-5.6.tar.gz (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.6MB/s \n",
            "\u001b[?25hCollecting dataclasses<0.7,>=0.6\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
            "Requirement already satisfied: importlib_metadata>=0.20 in /usr/local/lib/python3.6/dist-packages (from spacy-transformers) (1.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (3.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (2.0.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (42.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (0.9.6)\n",
            "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (7.3.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (1.17.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (2.21.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (0.4.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 38.2MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 36.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers<2.1.0,>=2.0.0->spacy-transformers) (4.28.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers<2.1.0,>=2.0.0->spacy-transformers) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers<2.1.0,>=2.0.0->spacy-transformers) (1.10.47)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy<6.0.0,>=5.0.0->spacy-transformers) (0.1.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib_metadata>=0.20->spacy-transformers) (0.6.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.3.0,>=2.2.1->spacy-transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.3.0,>=2.2.1->spacy-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.3.0,>=2.2.1->spacy-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.3.0,>=2.2.1->spacy-transformers) (2019.11.28)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<2.1.0,>=2.0.0->spacy-transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<2.1.0,>=2.0.0->spacy-transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<2.1.0,>=2.0.0->spacy-transformers) (0.14.1)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers<2.1.0,>=2.0.0->spacy-transformers) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers<2.1.0,>=2.0.0->spacy-transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers<2.1.0,>=2.0.0->spacy-transformers) (1.13.47)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from zipp>=0.5->importlib_metadata>=0.20->spacy-transformers) (8.0.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers<2.1.0,>=2.0.0->spacy-transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers<2.1.0,>=2.0.0->spacy-transformers) (0.15.2)\n",
            "Building wheels for collected packages: spacy-transformers, torchcontrib, ftfy, sacremoses\n",
            "  Building wheel for spacy-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spacy-transformers: filename=spacy_transformers-0.5.1-py2.py3-none-any.whl size=52837 sha256=974e7d9ca640f2389408df949d5e029cc92c1ce97d725a2bb8d4962751e1ff98\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/c2/17/625a3d14da8cabe9781ab1648d489d1b41a8a81dc289e5af1f\n",
            "  Building wheel for torchcontrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchcontrib: filename=torchcontrib-0.0.2-cp36-none-any.whl size=7530 sha256=28fb8a8cc4d14b00cdcc9a495d22d593756a165886f19c1bf3e2dd30bc80b09a\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/06/7b/a5f5920bbf4f12a2c927e438fac17d4cd9560f8336b00e9a99\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.6-cp36-none-any.whl size=44553 sha256=038b373a34f56d176c7a960ea219fe885ff2283088855839afec8f193a3572c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/34/ce/cbb38d71543c408de56f3c5e26ce8ba495a0fa5a28eaaf1046\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884629 sha256=0e35f1ec667859179fc171c6f4867cf004c384b6dd246410e2dcacdb4bb3c032\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built spacy-transformers torchcontrib ftfy sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, transformers, torchcontrib, ftfy, dataclasses, spacy-transformers\n",
            "  Found existing installation: dataclasses 0.7\n",
            "    Uninstalling dataclasses-0.7:\n",
            "      Successfully uninstalled dataclasses-0.7\n",
            "Successfully installed dataclasses-0.6 ftfy-5.6 sacremoses-0.0.38 sentencepiece-0.1.85 spacy-transformers-0.5.1 torchcontrib-0.0.2 transformers-2.0.0\n",
            "Collecting en_trf_distilbertbaseuncased_lg==2.2.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_trf_distilbertbaseuncased_lg-2.2.0/en_trf_distilbertbaseuncased_lg-2.2.0.tar.gz (245.0MB)\n",
            "\u001b[K     |████████████████████████████████| 245.0MB 98.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from en_trf_distilbertbaseuncased_lg==2.2.0) (2.2.3)\n",
            "Requirement already satisfied: spacy-transformers>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from en_trf_distilbertbaseuncased_lg==2.2.0) (0.5.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (42.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (0.9.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (2.0.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (0.6.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (2.21.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (1.17.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (3.0.2)\n",
            "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (7.3.1)\n",
            "Requirement already satisfied: torchcontrib<0.1.0,>=0.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (0.0.2)\n",
            "Requirement already satisfied: ftfy<6.0.0,>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (5.6)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (1.3.1)\n",
            "Requirement already satisfied: transformers<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (2.0.0)\n",
            "Requirement already satisfied: dataclasses<0.7,>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (1.3.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (1.24.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (4.28.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy<6.0.0,>=5.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (0.1.8)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (0.1.85)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (0.0.38)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (1.10.47)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (0.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (0.14.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (1.13.47)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (0.9.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (8.0.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (0.15.2)\n",
            "Building wheels for collected packages: en-trf-distilbertbaseuncased-lg\n",
            "  Building wheel for en-trf-distilbertbaseuncased-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-trf-distilbertbaseuncased-lg: filename=en_trf_distilbertbaseuncased_lg-2.2.0-cp36-none-any.whl size=245033117 sha256=5f22577624b13d90477d5ff2c2bbddfbab4c46d185e555eda8be89e81fe7c7e3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5ydm4b41/wheels/ed/90/91/d6d33eb6c8ac5696288f9c034cead21c5bcc1786d04625f69a\n",
            "Successfully built en-trf-distilbertbaseuncased-lg\n",
            "Installing collected packages: en-trf-distilbertbaseuncased-lg\n",
            "Successfully installed en-trf-distilbertbaseuncased-lg-2.2.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_trf_distilbertbaseuncased_lg')\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJHwnL15E3i1",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUIq-IpqE-w4",
        "colab_type": "code",
        "outputId": "fde3abe5-7f92-467b-ac44-c5c322ef1589",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "# REMEBER TO UPLOAD THIS!\n",
        "input_file = 'news_headlines.csv'\n",
        "\n",
        "TRAIN_DATA = []\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "list_of_sites = list(df['news_site'].unique())\n",
        "\n",
        "for row in df.iterrows():\n",
        "    row_headline = row[1][2].strip()\n",
        "    row_site     = row[1][1]\n",
        "    if row_headline:\n",
        "        # Add all the sites to the dict\n",
        "        row_cat            = {site: 0.0 for site in list_of_sites}\n",
        "        row_cat[row_site] += 1.0\n",
        "        TRAIN_DATA.append((row_headline.strip(), {\"cats\": row_cat}))\n",
        "print(TRAIN_DATA[0])\n",
        "df = None"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Experts say adapting to climate change can pay off manifold', {'cats': {'ABC - Tech': 1.0, 'ABC - Top Stories': 0.0, 'ABC - US': 0.0, 'ABC - World': 0.0, 'Al Jazeera': 0.0, 'AllAfrica News - Mozambique': 0.0, 'ARRL': 0.0, 'Ars Technica - all features': 0.0, 'Ars Technica - all news': 0.0, 'Axios - Business': 0.0, 'Axios - Energy': 0.0, 'Axios - Future': 0.0, 'Axios - Health Care': 0.0, 'Axios - Politics': 0.0, 'Axios - Science': 0.0, 'Axios - Technology': 0.0, 'Axios - Top': 0.0, 'Axios - World': 0.0, 'Bandladesh - bdnews24.com': 0.0, 'Bangkok Post - Lifestyle': 0.0, 'Bangkok Post - Most Recent': 0.0, 'Bangkok Post - Top Stories': 0.0, 'Bangkok Post - Travel': 0.0, 'BBC': 0.0, 'BBC - Africa': 0.0, 'BBC - Asia': 0.0, 'BBC - England': 0.0, 'BBC - Europe': 0.0, 'BBC - Latin America': 0.0, 'BBC - Middle East': 0.0, 'BBC - Northern Ireland': 0.0, 'BBC - Scotland': 0.0, 'BBC - UK': 0.0, 'BBC - US & Canada': 0.0, 'BBC - Wales': 0.0, 'BBC - World': 0.0, 'Breitbart \"News\"': 0.0, 'Buzzfeed - US News': 0.0, 'CanLii - Regulations': 0.0, 'CanLii - Supreme Court of Canada': 0.0, 'Caracas Chronicles - all': 0.0, 'CBC - Aboriginal': 0.0, 'CBC - Canada': 0.0, 'CBC - Politics': 0.0, 'CBC - Top Stories': 0.0, 'CBC - World': 0.0, 'CBS - 48 Hours': 0.0, 'CBS - 60 Minutes': 0.0, 'CBS - Politics': 0.0, 'CBS - Primary Source': 0.0, 'CBS - SciTech': 0.0, 'CBS - Strange': 0.0, 'CBS - TechTalk': 0.0, 'CBS - US': 0.0, 'CBS - World': 0.0, 'ChinaDaily - HK News': 0.0, 'ChinaDaily - News': 0.0, 'Civil.ge': 0.0, 'CNBC - Earnings Central': 0.0, 'CNBC - Economy': 0.0, 'CNBC - Energy': 0.0, 'CNBC - Investing': 0.0, 'CNBC - News': 0.0, 'CNBC - News Releases': 0.0, 'CNBC - Politics': 0.0, 'CNBC - Tech/Business': 0.0, 'CNET - News': 0.0, 'CNN - Politics': 0.0, 'CNN - Top Stories': 0.0, 'CTV News - Canada': 0.0, 'CTV News - Montreal Latest': 0.0, 'CTV News - Politics': 0.0, 'CTV News - Top Stories': 0.0, 'CTV News - World': 0.0, 'Daily Kos': 0.0, 'Daily Maverick': 0.0, 'Daily Post Nigeria - all': 0.0, 'Der Spiegel': 0.0, 'Der Spiegel - auf Deutsch': 0.0, 'Der Spiegel - Business News': 0.0, 'Der Spiegel - European News': 0.0, 'Der Spiegel - Germany News': 0.0, 'Der Spiegel - World News': 0.0, 'Der Spiegel - Zeitgeist': 0.0, 'Drudge Report': 0.0, 'DSL Reports': 0.0, 'Ed Felten - Freedom to Tinker': 0.0, 'EFF Updates': 0.0, 'en.publika.md': 0.0, 'eNCA - Top Stories': 0.0, 'EU vs DISINFORMATION': 0.0, 'FactCheck': 0.0, 'FactCheckNI': 0.0, 'Financial Times - Asia': 0.0, 'Financial Times - Europe': 0.0, 'Financial Times - India': 0.0, 'Financial Times - Middle East': 0.0, 'Financial Times - UK': 0.0, 'Financial Times - US': 0.0, 'FiveThirtyEight - All': 0.0, 'FiveThirtyEight - Nate Silver': 0.0, 'FoxNews': 0.0, 'FoxNews - Politics': 0.0, 'france24': 0.0, 'freenode': 0.0, 'Futura Sciences': 0.0, 'GlobalNews.ca': 0.0, 'GlobalNews.ca - Canada': 0.0, 'GlobalNews.ca - Politics': 0.0, 'GlobalNews.ca - World': 0.0, 'Goo2019-11-20 10:19:18\\tℹ \\tTopic for ##news is \"[world': 0.0, 'Google News - \"Catalonia\"': 0.0, 'Google News - \"Iran\"': 0.0, 'Google News - \"North Korea\"': 0.0, 'Google News - \"Palestine\"': 0.0, 'Google News - \"Palestinian\"': 0.0, 'Google News - \"Russia\"': 0.0, 'Google News - \"spain\"': 0.0, 'Google News - \"Syria\"': 0.0, 'Google News - \"Turkey\"': 0.0, 'Google News - Canada': 0.0, 'Google News - Canada - Top Stories': 0.0, 'Google News - Health': 0.0, 'Google News - India': 0.0, 'Google News - Ireland': 0.0, 'Google News - Israel': 0.0, 'Google News - Malaysia': 0.0, 'Google News - Pakistan': 0.0, 'Google News - Philippines': 0.0, 'Google News - Science': 0.0, 'Google News - Singapore': 0.0, 'Google News - South Africa': 0.0, 'Google News - Technology': 0.0, 'Google News - Uganda': 0.0, 'Google News - UK': 0.0, 'Google News - US': 0.0, 'Google News - US Business': 0.0, 'Google News - Venezuela': 0.0, 'Google News - World': 0.0, 'Google News - Zimbabwe': 0.0, 'Gossip Cop': 0.0, 'Haaretz - All Headlines': 0.0, 'Haaretz - Israel News': 0.0, 'Haaretz - WorldNews': 0.0, 'Hacker News': 0.0, 'Hoax Slayer': 0.0, 'HRC': 0.0, 'Huffington Post - Business News': 0.0, 'Huffington Post - Education News': 0.0, 'Huffington Post - Money': 0.0, 'Huffington Post - Politics': 0.0, 'Huffington Post - Religion': 0.0, 'Huffington Post - Weird News': 0.0, 'Independent - Business': 0.0, 'Independent - Education': 0.0, 'Independent - Media': 0.0, 'Independent - Money': 0.0, 'Independent - News': 0.0, 'Independent - Science': 0.0, 'Independent - UK': 0.0, 'Independent - World': 0.0, 'infowars': 0.0, 'ISC': 0.0, 'Japan Today': 0.0, 'Journal du hacker': 0.0, 'JPost - Arab Israeli Conflict': 0.0, 'JPost - BDS Movement': 0.0, 'JPost - Breaking News': 0.0, 'JPost - Gaza News': 0.0, 'Laotian Times - all': 0.0, 'Lead Stories': 0.0, 'LGBTQ Nation - all': 0.0, 'Mail & Guardian': 0.0, 'Media Bias/Fact Check': 0.0, 'Metabunk': 0.0, 'Metro - The Guardian Nigeria': 0.0, 'MetroNews - Canada': 0.0, 'MetroNews - Toronto': 0.0, 'MetroNews - World': 0.0, 'Mexico News Daily': 0.0, 'MotherJones - all': 0.0, 'MSNBC - Latest Headlines': 0.0, 'NBC - Politics': 0.0, 'NBC - Top Stories': 0.0, 'NBC - US': 0.0, 'Nepali Times - all': 0.0, 'New Statesman': 0.0, 'New Statesmen - Politics': 0.0, 'News24 - Africa': 0.0, 'News24 - South Africa': 0.0, 'News24 - Top Stories': 0.0, 'News24 - World': 0.0, 'Newsy - All Videos': 0.0, 'Nikkei Asian Review': 0.0, 'North Korea News.org - all': 0.0, 'North Korean Times - Latest': 0.0, 'Novinite (Bulgarian)': 0.0, 'NPR - Arts': 0.0, 'NPR - Business': 0.0, 'NPR - Health & Science': 0.0, 'NPR - Middle East': 0.0, 'NPR - News': 0.0, 'NPR - Politics': 0.0, 'NPR - Research News': 0.0, 'NPR - Space': 0.0, 'NPR - U.S. News': 0.0, 'NPR - World News': 0.0, 'NY Post': 0.0, 'NYT - Africa': 0.0, 'NYT - Americas': 0.0, 'NYT - Asia Pacific': 0.0, 'NYT - Business': 0.0, 'NYT - Europe': 0.0, 'NYT - Middle East': 0.0, 'NYT - Science': 0.0, 'NYT - Technology': 0.0, 'NYT - US': 0.0, 'NYT - US Politics': 0.0, 'NYT - Wire': 0.0, 'NYT - World News': 0.0, 'OANN - all': 0.0, 'OANN - Business': 0.0, 'OANN - Economy': 0.0, 'OANN - Money': 0.0, 'OANN - Tech': 0.0, 'OANN - Top News': 0.0, 'OANN - World': 0.0, 'PBS - NewsHour The Latest': 0.0, 'Peruvian Times': 0.0, 'Phoronix': 0.0, 'Politico - Congress': 0.0, 'Politico - Defense': 0.0, 'Politico - Economy': 0.0, 'Politico - Energy & Environment': 0.0, 'Politico - Health Care': 0.0, 'Politico - Picks': 0.0, 'Politico - Politics': 0.0, 'Politifact - Articles': 0.0, 'Politifact - Statements': 0.0, 'ProPublica - Main': 0.0, 'pulse.ng - Local': 0.0, 'Radio-Canada Nouvelles': 0.0, 'Rasmussen Reports': 0.0, 'Raw Story': 0.0, 'Real Clear Poltics': 0.0, 'Reason.com - Articles': 0.0, 'Reddit - /r/Europe': 0.0, 'Reddit - /r/netsec': 0.0, 'Reddit - /r/news': 0.0, 'Reddit - /r/politics': 0.0, 'Reddit - /r/TrueReddit': 0.0, 'Reddit - /r/UpliftingNews': 0.0, 'Reddit - /r/WorldNews - New': 0.0, 'Reddit - Russia Lago': 0.0, 'Reuters - Arts': 0.0, 'Reuters - Business': 0.0, 'Reuters - Company News': 0.0, 'Reuters - Entertainment': 0.0, 'Reuters - Environment': 0.0, 'Reuters - Health News': 0.0, 'Reuters - Lifestyle': 0.0, 'Reuters - Money': 0.0, 'Reuters - Most Watched Video': 0.0, 'Reuters - Oddly Enough': 0.0, 'Reuters - People': 0.0, 'Reuters - Pictures': 0.0, 'Reuters - Politics': 0.0, 'Reuters - Politics Video': 0.0, 'Reuters - Science': 0.0, 'Reuters - Sports': 0.0, 'Reuters - Technology': 0.0, 'Reuters - Top News': 0.0, 'Reuters - Top News Video': 0.0, 'Reuters - US News': 0.0, 'Reuters - World': 0.0, 'Reuters - World News Video': 0.0, 'RightWingWatch': 0.0, 'Rio Times - All': 0.0, 'RollCall - All': 0.0, 'RollCall - Heard on the Hill': 0.0, 'RollCall - News without Opinion': 0.0, 'RollCall - Opinion/Analysis': 0.0, 'RollCall - Policy': 0.0, 'RollCall - Rothenblog': 0.0, 'Romania Insider - all': 0.0, 'RT': 0.0, 'SABC News': 0.0, 'Science Daily - all': 0.0, 'SCOTUSblog': 0.0, 'Sky News': 0.0, 'Sky News - Business': 0.0, 'Sky News - Politics': 0.0, 'Sky News - Strange News': 0.0, 'Sky News - Technology': 0.0, 'Sky News - UK': 0.0, 'Sky News - US': 0.0, 'Sky News - World': 0.0, 'Slate - Main': 0.0, 'Slate - Politics': 0.0, 'Slate - Science': 0.0, 'Smithsonian Science': 0.0, 'Snopes': 0.0, 'South China Morning Post - (China) Diplomacy & Defense': 0.0, 'South China Morning Post - (China) Economy': 0.0, 'South China Morning Post - (China) Money & Wealth': 0.0, 'South China Morning Post - (China) Policies & Politics': 0.0, 'South China Morning Post - (China) Society': 0.0, 'South China Morning Post - (HK) Economy': 0.0, 'South China Morning Post - (HK) Law & Crime': 0.0, 'South China Morning Post - (HK) Politics': 0.0, 'South China Morning Post - Asia': 0.0, 'South China Morning Post - China': 0.0, 'South China Morning Post - Hong Kong': 0.0, 'South China Morning Post - News': 0.0, 'South China Morning Post - World': 0.0, 'South China MP - (Business) China Economy': 0.0, 'South China MP - Africa': 0.0, 'South China MP - Americas': 0.0, 'South China MP - Arts & Entertainment': 0.0, 'South China MP - Australasia': 0.0, 'South China MP - Culture': 0.0, 'South China MP - East Asia': 0.0, 'South China MP - Europe': 0.0, 'South China MP - Film & TV': 0.0, 'South China MP - Life': 0.0, 'South China MP - Middle East': 0.0, 'South China MP - Music': 0.0, 'South China MP - Property HK / China': 0.0, 'South China MP - Russia & Central Asia': 0.0, 'South China MP - Southeast Asia': 0.0, 'South China MP - This Week in Asia': 0.0, 'South China MP - TWIA Business': 0.0, 'South China MP - TWIA Opinion': 0.0, 'South China MP - TWIA Politics': 0.0, 'South China MP - USA': 0.0, 'SowetanLIVE': 0.0, 'SRN News': 0.0, 'SWI - Top News': 0.0, 'Sydney Anglicans - All News': 0.0, 'Sydney Morning Herald - Business': 0.0, 'Sydney Morning Herald - National': 0.0, 'Sydney Morning Herald - Technology': 0.0, 'Sydney Morning Herald - Top Stories': 0.0, 'Sydney Morning Herald - World': 0.0, 'Syrian Arab News Agency - all': 0.0, 'Taipei Times - all': 0.0, 'Taipei Times - Bilingual': 0.0, 'Taipei Times - Local News': 0.0, 'Taipei Times - World': 0.0, 'Taiwan Today - Top News': 0.0, 'techdirt': 0.0, 'Telegraph - Business': 0.0, 'Telegraph - Latest News': 0.0, 'Telegraph - News': 0.0, 'Telegraph - Politics': 0.0, 'Telegraph - Science': 0.0, 'Telegraph - Technology': 0.0, 'Thai PBS World': 0.0, 'Thailand News - Breaking': 0.0, 'The Atlantic - all': 0.0, 'The Atlantic - Global': 0.0, 'The Atlantic - Politics': 0.0, 'The Bali Times - all': 0.0, 'The Baltic Times - all': 0.0, 'The Citizen': 0.0, 'The Costa Rica News': 0.0, 'The Daily Caller - all': 0.0, 'The Gateway Pundit': 0.0, 'The Guardian - UK': 0.0, 'The Guardian - US': 0.0, 'The Hill - Administration': 0.0, 'The Hill - All News': 0.0, 'The Hill - Campaign': 0.0, 'The Hill - House': 0.0, 'The Hill - Senate': 0.0, 'The Himalayan Times - all': 0.0, 'The Intercept': 0.0, 'The Krakow Post - all': 0.0, 'The Local (Germany)': 0.0, 'The Local (Spain)': 0.0, 'The Moscow Times - News': 0.0, 'The Moscow Times - Opinion': 0.0, 'The Nation': 0.0, 'The Real News Network': 0.0, 'The Romania Journal - all': 0.0, 'The Slovak Spectator': 0.0, 'The Slovak Spectator - title': 0.0, 'The Sofia Globe (Bulgaria)': 0.0, 'The Standard (HK) - Latest News': 0.0, 'The Tico Times - Costa Rica News': 0.0, 'TheJournal': 0.0, 'Time - Blog: Politics, Swampland': 0.0, 'Time - Business': 0.0, 'Time - Health': 0.0, 'Time - Newsfeed': 0.0, 'Time - Science': 0.0, 'Time - Tech': 0.0, 'Time - Top Stories': 0.0, 'Time - World': 0.0, 'Times Colonist - All': 0.0, 'Times Colonist - B.C.': 0.0, 'Times Colonist - Business': 0.0, 'Times Colonist - News': 0.0, 'Times of India - China': 0.0, 'Times of India - Education': 0.0, 'Times of India - Environment': 0.0, 'Times of India - Europe': 0.0, 'Times of India - India': 0.0, 'Times of India - Mad, Mad World': 0.0, 'Times of India - Middle East': 0.0, 'Times of India - News (Video)': 0.0, 'Times of India - NRI': 0.0, 'Times of India - South Asia': 0.0, 'Times of India - Top Stories': 0.0, 'Times of India - UK': 0.0, 'Times of India - US': 0.0, 'Times of India - World': 0.0, 'Tonga Broadcasting': 0.0, 'TorrentFreak': 0.0, 'TownHall - Latest Breaking News': 0.0, 'TownHall - Political': 0.0, 'TownHall - Science & Tech': 0.0, 'Truth or Fiction': 0.0, 'UN News Service': 0.0, 'USA.gov Updates': 0.0, 'VICE News - News': 0.0, 'Voice of Russia': 0.0, 'Washington Post - Fact Checker': 0.0, 'Washington Post - National News': 0.0, 'Washington Post - Politics': 0.0, 'Washington Post - World News': 0.0, 'Washington Times - Culture': 0.0, 'Washington Times - National': 0.0, 'Washington Times - News': 0.0, 'Washington Times - Politics': 0.0, 'Washington Times - Tech': 0.0, 'Wikinews': 0.0, 'Wired': 0.0, 'WTFJHT': 0.0, 'XKCD': 0.0, 'Yahoo News': 0.0, 'Yahoo News - Politics': 0.0, 'Yahoo News - Top Stories': 0.0, 'yam.md Moldova': 0.0, 'Zawya - Exclusive': 0.0, 'Zawya - Latest': 0.0, 'Zawya - Top Markets': 0.0, 'Zawya - Top Regional': 0.0, 'Zehabesha - all': 0.0, 'ZeroHedge - News': 0.0}})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9bc2FN-e5nP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RUN THIS TO MAKE SURE THAT SPACY IS WORKING\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_trf_distilbertbaseuncased_lg')\n",
        "doc = nlp(\"Apple shares rose on the news. Apple pie is delicious.\")\n",
        "print(doc[0].similarity(doc[7]))\n",
        "print(doc._.trf_last_hidden_state.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQJuNlC7hHra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_DATA = [\n",
        "    (\"text1\", {\"cats\": {\"POSITIVE\": 1.0, \"NEGATIVE\": 0.0, \"TESTING\": 0.0}})\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhsoEOcNhLag",
        "colab_type": "code",
        "outputId": "b31ccfaa-0afb-446f-fa74-dc06ad1130a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import spacy\n",
        "import random\n",
        "import torch\n",
        "\n",
        "from spacy.util         import minibatch\n",
        "from spacy_transformers import TransformersLanguage, TransformersWordPiecer, TransformersTok2Vec\n",
        "\n",
        "BATCH_SIZE = 1000\n",
        "ITERATIONS = 10\n",
        "MODEL      = \"distilbert-base-uncased\"\n",
        "\n",
        "is_using_gpu = spacy.prefer_gpu()\n",
        "if is_using_gpu:\n",
        "    print(\"USING GPU\")\n",
        "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
        "\n",
        "print(f\"Number of lables: {len(list_of_sites)}\")\n",
        "print(f\"Number of training data: {len(TRAIN_DATA)}\")\n",
        "\n",
        "nlp = spacy.load(\"en_trf_distilbertbaseuncased_lg\")\n",
        "print(nlp.pipe_names) # [\"sentencizer\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
        "textnews = nlp.create_pipe(\"trf_textcat\", config={\"exclusive_classes\": True})\n",
        "for label in list_of_sites:\n",
        "    textnews.add_label(label)\n",
        "nlp.add_pipe(textnews)\n",
        "optimizer = nlp.resume_training()\n",
        "for i in range(ITERATIONS):\n",
        "    random.shuffle(TRAIN_DATA)\n",
        "    losses = {}\n",
        "    for x, batch in enumerate(minibatch(TRAIN_DATA, size=BATCH_SIZE)):\n",
        "        texts, news = zip(*batch)\n",
        "        nlp.update(texts, news, sgd=optimizer, losses=losses)\n",
        "        print(f\"Batch number: {x}, Losses: {losses}\")\n",
        "    print(f\"Iteration: {i}, Losses: {losses}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "USING GPU\n",
            "Number of lables: 450\n",
            "Number of training data: 240403\n",
            "['sentencizer', 'trf_wordpiecer', 'trf_tok2vec']\n",
            "Batch number: 0, Losses: {'trf_textcat': 9.977775334846228e-07}\n",
            "Batch number: 1, Losses: {'trf_textcat': 1.9948261069657747e-06}\n",
            "Batch number: 2, Losses: {'trf_textcat': 2.9914152719356935e-06}\n",
            "Batch number: 3, Losses: {'trf_textcat': 3.992617848780355e-06}\n",
            "Batch number: 4, Losses: {'trf_textcat': 4.9933621539821615e-06}\n",
            "Batch number: 5, Losses: {'trf_textcat': 5.991247007841594e-06}\n",
            "Batch number: 6, Losses: {'trf_textcat': 6.985121899560909e-06}\n",
            "Batch number: 7, Losses: {'trf_textcat': 7.977671316439228e-06}\n",
            "Batch number: 8, Losses: {'trf_textcat': 8.96958783869195e-06}\n",
            "Batch number: 9, Losses: {'trf_textcat': 9.959822023120068e-06}\n",
            "Batch number: 10, Losses: {'trf_textcat': 1.0949302009066741e-05}\n",
            "Batch number: 11, Losses: {'trf_textcat': 1.1938313377868326e-05}\n",
            "Batch number: 12, Losses: {'trf_textcat': 1.2927580996802135e-05}\n",
            "Batch number: 13, Losses: {'trf_textcat': 1.3916652051193523e-05}\n",
            "Batch number: 14, Losses: {'trf_textcat': 1.4905317812008434e-05}\n",
            "Batch number: 15, Losses: {'trf_textcat': 1.5893738577688055e-05}\n",
            "Batch number: 16, Losses: {'trf_textcat': 1.6883426724234596e-05}\n",
            "Batch number: 17, Losses: {'trf_textcat': 1.787383678220067e-05}\n",
            "Batch number: 18, Losses: {'trf_textcat': 1.88616282912335e-05}\n",
            "Batch number: 19, Losses: {'trf_textcat': 1.984971027013671e-05}\n",
            "Batch number: 20, Losses: {'trf_textcat': 2.0839218564105977e-05}\n",
            "Batch number: 21, Losses: {'trf_textcat': 2.182814762363705e-05}\n",
            "Batch number: 22, Losses: {'trf_textcat': 2.2816548153059557e-05}\n",
            "Batch number: 23, Losses: {'trf_textcat': 2.3804721195119782e-05}\n",
            "Batch number: 24, Losses: {'trf_textcat': 2.4793596480776614e-05}\n",
            "Batch number: 25, Losses: {'trf_textcat': 2.578269709374581e-05}\n",
            "Batch number: 26, Losses: {'trf_textcat': 2.6770615022542188e-05}\n",
            "Batch number: 27, Losses: {'trf_textcat': 2.7759167323893053e-05}\n",
            "Batch number: 28, Losses: {'trf_textcat': 2.874899189464486e-05}\n",
            "Batch number: 29, Losses: {'trf_textcat': 2.9738904913756414e-05}\n",
            "Batch number: 30, Losses: {'trf_textcat': 3.0726992235941e-05}\n",
            "Batch number: 31, Losses: {'trf_textcat': 3.1715188583802956e-05}\n",
            "Batch number: 32, Losses: {'trf_textcat': 3.2704226214264054e-05}\n",
            "Batch number: 33, Losses: {'trf_textcat': 3.369122953245096e-05}\n",
            "Batch number: 34, Losses: {'trf_textcat': 3.468105364845542e-05}\n",
            "Batch number: 35, Losses: {'trf_textcat': 3.566948771549505e-05}\n",
            "Batch number: 36, Losses: {'trf_textcat': 3.665659812668309e-05}\n",
            "Batch number: 37, Losses: {'trf_textcat': 3.7645163956767647e-05}\n",
            "Batch number: 38, Losses: {'trf_textcat': 3.8633175222457794e-05}\n",
            "Batch number: 39, Losses: {'trf_textcat': 3.962189919093362e-05}\n",
            "Batch number: 40, Losses: {'trf_textcat': 4.0610826545162126e-05}\n",
            "Batch number: 41, Losses: {'trf_textcat': 4.159901357070339e-05}\n",
            "Batch number: 42, Losses: {'trf_textcat': 4.2586115910125955e-05}\n",
            "Batch number: 43, Losses: {'trf_textcat': 4.357423006240424e-05}\n",
            "Batch number: 44, Losses: {'trf_textcat': 4.456219664916716e-05}\n",
            "Batch number: 45, Losses: {'trf_textcat': 4.555007853923598e-05}\n",
            "Batch number: 46, Losses: {'trf_textcat': 4.653823702938098e-05}\n",
            "Batch number: 47, Losses: {'trf_textcat': 4.752698362153751e-05}\n",
            "Batch number: 48, Losses: {'trf_textcat': 4.851538915318088e-05}\n",
            "Batch number: 49, Losses: {'trf_textcat': 4.9505106858305226e-05}\n",
            "Batch number: 50, Losses: {'trf_textcat': 5.049371111454093e-05}\n",
            "Batch number: 51, Losses: {'trf_textcat': 5.148223476680869e-05}\n",
            "Batch number: 52, Losses: {'trf_textcat': 5.2470063906184805e-05}\n",
            "Batch number: 53, Losses: {'trf_textcat': 5.34593121983562e-05}\n",
            "Batch number: 54, Losses: {'trf_textcat': 5.4448207379209634e-05}\n",
            "Batch number: 55, Losses: {'trf_textcat': 5.543722568290832e-05}\n",
            "Batch number: 56, Losses: {'trf_textcat': 5.642552264362166e-05}\n",
            "Batch number: 57, Losses: {'trf_textcat': 5.7413731269662094e-05}\n",
            "Batch number: 58, Losses: {'trf_textcat': 5.840122867084574e-05}\n",
            "Batch number: 59, Losses: {'trf_textcat': 5.938910419445165e-05}\n",
            "Batch number: 60, Losses: {'trf_textcat': 6.0377811450962326e-05}\n",
            "Batch number: 61, Losses: {'trf_textcat': 6.136584192972805e-05}\n",
            "Batch number: 62, Losses: {'trf_textcat': 6.235442731394869e-05}\n",
            "Batch number: 63, Losses: {'trf_textcat': 6.334230010907049e-05}\n",
            "Batch number: 64, Losses: {'trf_textcat': 6.433048235976457e-05}\n",
            "Batch number: 65, Losses: {'trf_textcat': 6.531947826715623e-05}\n",
            "Batch number: 66, Losses: {'trf_textcat': 6.63078133129602e-05}\n",
            "Batch number: 67, Losses: {'trf_textcat': 6.7296303313924e-05}\n",
            "Batch number: 68, Losses: {'trf_textcat': 6.828535197200836e-05}\n",
            "Batch number: 69, Losses: {'trf_textcat': 6.927274807821959e-05}\n",
            "Batch number: 70, Losses: {'trf_textcat': 7.026000503174146e-05}\n",
            "Batch number: 71, Losses: {'trf_textcat': 7.124795877189172e-05}\n",
            "Batch number: 72, Losses: {'trf_textcat': 7.223606894513068e-05}\n",
            "Batch number: 73, Losses: {'trf_textcat': 7.322516785279731e-05}\n",
            "Batch number: 74, Losses: {'trf_textcat': 7.42137051474856e-05}\n",
            "Batch number: 75, Losses: {'trf_textcat': 7.520192980337015e-05}\n",
            "Batch number: 76, Losses: {'trf_textcat': 7.618993288360798e-05}\n",
            "Batch number: 77, Losses: {'trf_textcat': 7.717832136222569e-05}\n",
            "Batch number: 78, Losses: {'trf_textcat': 7.816718812136969e-05}\n",
            "Batch number: 79, Losses: {'trf_textcat': 7.915487435639079e-05}\n",
            "Batch number: 80, Losses: {'trf_textcat': 8.014252796328947e-05}\n",
            "Batch number: 81, Losses: {'trf_textcat': 8.112996476938861e-05}\n",
            "Batch number: 82, Losses: {'trf_textcat': 8.211768704313727e-05}\n",
            "Batch number: 83, Losses: {'trf_textcat': 8.310536429689819e-05}\n",
            "Batch number: 84, Losses: {'trf_textcat': 8.409389067765005e-05}\n",
            "Batch number: 85, Losses: {'trf_textcat': 8.508234816417826e-05}\n",
            "Batch number: 86, Losses: {'trf_textcat': 8.606981191405794e-05}\n",
            "Batch number: 87, Losses: {'trf_textcat': 8.705857317181653e-05}\n",
            "Batch number: 88, Losses: {'trf_textcat': 8.804616186353087e-05}\n",
            "Batch number: 89, Losses: {'trf_textcat': 8.90342945467637e-05}\n",
            "Batch number: 90, Losses: {'trf_textcat': 9.002294734727911e-05}\n",
            "Batch number: 91, Losses: {'trf_textcat': 9.101152033963444e-05}\n",
            "Batch number: 92, Losses: {'trf_textcat': 9.1998916218472e-05}\n",
            "Batch number: 93, Losses: {'trf_textcat': 9.298654538270057e-05}\n",
            "Batch number: 94, Losses: {'trf_textcat': 9.397466374139185e-05}\n",
            "Batch number: 95, Losses: {'trf_textcat': 9.49627190038882e-05}\n",
            "Batch number: 96, Losses: {'trf_textcat': 9.595024801001273e-05}\n",
            "Batch number: 97, Losses: {'trf_textcat': 9.693853621683957e-05}\n",
            "Batch number: 98, Losses: {'trf_textcat': 9.792569414912577e-05}\n",
            "Batch number: 99, Losses: {'trf_textcat': 9.891235777104157e-05}\n",
            "Batch number: 100, Losses: {'trf_textcat': 9.990039086460456e-05}\n",
            "Batch number: 101, Losses: {'trf_textcat': 0.00010088787450968084}\n",
            "Batch number: 102, Losses: {'trf_textcat': 0.0001018772625229758}\n",
            "Batch number: 103, Losses: {'trf_textcat': 0.0001028654918400207}\n",
            "Batch number: 104, Losses: {'trf_textcat': 0.00010385288089764799}\n",
            "Batch number: 105, Losses: {'trf_textcat': 0.00010484048266334867}\n",
            "Batch number: 106, Losses: {'trf_textcat': 0.00010582847824025521}\n",
            "Batch number: 107, Losses: {'trf_textcat': 0.00010681720118554949}\n",
            "Batch number: 108, Losses: {'trf_textcat': 0.00010780618424632848}\n",
            "Batch number: 109, Losses: {'trf_textcat': 0.00010879572005251248}\n",
            "Batch number: 110, Losses: {'trf_textcat': 0.00010978325371979736}\n",
            "Batch number: 111, Losses: {'trf_textcat': 0.00011077158023908851}\n",
            "Batch number: 112, Losses: {'trf_textcat': 0.00011175911777172587}\n",
            "Batch number: 113, Losses: {'trf_textcat': 0.00011274904090896598}\n",
            "Batch number: 114, Losses: {'trf_textcat': 0.0001137376862061501}\n",
            "Batch number: 115, Losses: {'trf_textcat': 0.00011472632559161866}\n",
            "Batch number: 116, Losses: {'trf_textcat': 0.00011571453501346696}\n",
            "Batch number: 117, Losses: {'trf_textcat': 0.00011670210028569272}\n",
            "Batch number: 118, Losses: {'trf_textcat': 0.00011769104071390757}\n",
            "Batch number: 119, Losses: {'trf_textcat': 0.00011867900047946023}\n",
            "Batch number: 120, Losses: {'trf_textcat': 0.00011966793931605935}\n",
            "Batch number: 121, Losses: {'trf_textcat': 0.00012065685268680681}\n",
            "Batch number: 122, Losses: {'trf_textcat': 0.00012164402778580552}\n",
            "Batch number: 123, Losses: {'trf_textcat': 0.00012263313988114533}\n",
            "Batch number: 124, Losses: {'trf_textcat': 0.00012362187101189193}\n",
            "Batch number: 125, Losses: {'trf_textcat': 0.00012461078301839734}\n",
            "Batch number: 126, Losses: {'trf_textcat': 0.00012559917001908616}\n",
            "Batch number: 127, Losses: {'trf_textcat': 0.00012658844116231194}\n",
            "Batch number: 128, Losses: {'trf_textcat': 0.00012757680849517783}\n",
            "Batch number: 129, Losses: {'trf_textcat': 0.00012856523972004652}\n",
            "Batch number: 130, Losses: {'trf_textcat': 0.0001295541567287728}\n",
            "Batch number: 131, Losses: {'trf_textcat': 0.00013054297744474752}\n",
            "Batch number: 132, Losses: {'trf_textcat': 0.00013153172767488286}\n",
            "Batch number: 133, Losses: {'trf_textcat': 0.00013252011331132962}\n",
            "Batch number: 134, Losses: {'trf_textcat': 0.00013350840879411408}\n",
            "Batch number: 135, Losses: {'trf_textcat': 0.00013449686707645014}\n",
            "Batch number: 136, Losses: {'trf_textcat': 0.00013548569097565633}\n",
            "Batch number: 137, Losses: {'trf_textcat': 0.00013647266564476013}\n",
            "Batch number: 138, Losses: {'trf_textcat': 0.00013746013735271845}\n",
            "Batch number: 139, Losses: {'trf_textcat': 0.00013844713646449236}\n",
            "Batch number: 140, Losses: {'trf_textcat': 0.00013943596752596932}\n",
            "Batch number: 141, Losses: {'trf_textcat': 0.0001404248655489937}\n",
            "Batch number: 142, Losses: {'trf_textcat': 0.00014141189831207157}\n",
            "Batch number: 143, Losses: {'trf_textcat': 0.00014240063785564416}\n",
            "Batch number: 144, Losses: {'trf_textcat': 0.00014338869073071692}\n",
            "Batch number: 145, Losses: {'trf_textcat': 0.00014437754578011663}\n",
            "Batch number: 146, Losses: {'trf_textcat': 0.00014536539777054713}\n",
            "Batch number: 147, Losses: {'trf_textcat': 0.0001463545880824313}\n",
            "Batch number: 148, Losses: {'trf_textcat': 0.0001473434801937401}\n",
            "Batch number: 149, Losses: {'trf_textcat': 0.00014833064631147863}\n",
            "Batch number: 150, Losses: {'trf_textcat': 0.00014931769840131892}\n",
            "Batch number: 151, Losses: {'trf_textcat': 0.0001503050714291021}\n",
            "Batch number: 152, Losses: {'trf_textcat': 0.00015129386270018585}\n",
            "Batch number: 153, Losses: {'trf_textcat': 0.0001522831738611785}\n",
            "Batch number: 154, Losses: {'trf_textcat': 0.00015327082405747205}\n",
            "Batch number: 155, Losses: {'trf_textcat': 0.0001542582909905832}\n",
            "Batch number: 156, Losses: {'trf_textcat': 0.00015524648154041643}\n",
            "Batch number: 157, Losses: {'trf_textcat': 0.00015623525314367726}\n",
            "Batch number: 158, Losses: {'trf_textcat': 0.00015722485534297448}\n",
            "Batch number: 159, Losses: {'trf_textcat': 0.00015821380611669156}\n",
            "Batch number: 160, Losses: {'trf_textcat': 0.0001592018336395995}\n",
            "Batch number: 161, Losses: {'trf_textcat': 0.00016018984547372384}\n",
            "Batch number: 162, Losses: {'trf_textcat': 0.00016117735958687263}\n",
            "Batch number: 163, Losses: {'trf_textcat': 0.0001621656210772926}\n",
            "Batch number: 164, Losses: {'trf_textcat': 0.00016315351160756109}\n",
            "Batch number: 165, Losses: {'trf_textcat': 0.00016414228366556927}\n",
            "Batch number: 166, Losses: {'trf_textcat': 0.0001651307617294151}\n",
            "Batch number: 167, Losses: {'trf_textcat': 0.00016611840737823513}\n",
            "Batch number: 168, Losses: {'trf_textcat': 0.00016710669012809376}\n",
            "Batch number: 169, Losses: {'trf_textcat': 0.00016809625299174513}\n",
            "Batch number: 170, Losses: {'trf_textcat': 0.000169083713103646}\n",
            "Batch number: 171, Losses: {'trf_textcat': 0.00017007169458338467}\n",
            "Batch number: 172, Losses: {'trf_textcat': 0.00017105979463849508}\n",
            "Batch number: 173, Losses: {'trf_textcat': 0.00017204872813181282}\n",
            "Batch number: 174, Losses: {'trf_textcat': 0.00017303697723036748}\n",
            "Batch number: 175, Losses: {'trf_textcat': 0.00017402387857146095}\n",
            "Batch number: 176, Losses: {'trf_textcat': 0.00017501313891443715}\n",
            "Batch number: 177, Losses: {'trf_textcat': 0.00017600064518319414}\n",
            "Batch number: 178, Losses: {'trf_textcat': 0.00017698981707781059}\n",
            "Batch number: 179, Losses: {'trf_textcat': 0.00017797801228880417}\n",
            "Batch number: 180, Losses: {'trf_textcat': 0.0001789668839364822}\n",
            "Batch number: 181, Losses: {'trf_textcat': 0.00017995550047089637}\n",
            "Batch number: 182, Losses: {'trf_textcat': 0.0001809421439702419}\n",
            "Batch number: 183, Losses: {'trf_textcat': 0.0001819303513457271}\n",
            "Batch number: 184, Losses: {'trf_textcat': 0.00018291738797415746}\n",
            "Batch number: 185, Losses: {'trf_textcat': 0.00018390572427051666}\n",
            "Batch number: 186, Losses: {'trf_textcat': 0.00018489355875317415}\n",
            "Batch number: 187, Losses: {'trf_textcat': 0.00018588246553008503}\n",
            "Batch number: 188, Losses: {'trf_textcat': 0.00018687023225538724}\n",
            "Batch number: 189, Losses: {'trf_textcat': 0.00018785899487738789}\n",
            "Batch number: 190, Losses: {'trf_textcat': 0.00018884639041516493}\n",
            "Batch number: 191, Losses: {'trf_textcat': 0.00018983517281867535}\n",
            "Batch number: 192, Losses: {'trf_textcat': 0.00019082303174400295}\n",
            "Batch number: 193, Losses: {'trf_textcat': 0.00019181101697540726}\n",
            "Batch number: 194, Losses: {'trf_textcat': 0.00019279992841347848}\n",
            "Batch number: 195, Losses: {'trf_textcat': 0.00019378639626665972}\n",
            "Batch number: 196, Losses: {'trf_textcat': 0.0001947738419403322}\n",
            "Batch number: 197, Losses: {'trf_textcat': 0.00019576263628096058}\n",
            "Batch number: 198, Losses: {'trf_textcat': 0.00019675009639286145}\n",
            "Batch number: 199, Losses: {'trf_textcat': 0.0001977388201339636}\n",
            "Batch number: 200, Losses: {'trf_textcat': 0.00019872801533438178}\n",
            "Batch number: 201, Losses: {'trf_textcat': 0.00019971599601831258}\n",
            "Batch number: 202, Losses: {'trf_textcat': 0.00020070497862434422}\n",
            "Batch number: 203, Losses: {'trf_textcat': 0.0002016935577557888}\n",
            "Batch number: 204, Losses: {'trf_textcat': 0.0002026808633672772}\n",
            "Batch number: 205, Losses: {'trf_textcat': 0.0002036685065149868}\n",
            "Batch number: 206, Losses: {'trf_textcat': 0.00020465659974888695}\n",
            "Batch number: 207, Losses: {'trf_textcat': 0.0002056432280141962}\n",
            "Batch number: 208, Losses: {'trf_textcat': 0.00020663215707372729}\n",
            "Batch number: 209, Losses: {'trf_textcat': 0.00020762178371569462}\n",
            "Batch number: 210, Losses: {'trf_textcat': 0.00020860916470155644}\n",
            "Batch number: 211, Losses: {'trf_textcat': 0.00020959731261882553}\n",
            "Batch number: 212, Losses: {'trf_textcat': 0.00021058524748696072}\n",
            "Batch number: 213, Losses: {'trf_textcat': 0.0002115743455988195}\n",
            "Batch number: 214, Losses: {'trf_textcat': 0.0002125631915532722}\n",
            "Batch number: 215, Losses: {'trf_textcat': 0.00021355145293000533}\n",
            "Batch number: 216, Losses: {'trf_textcat': 0.00021454102898132987}\n",
            "Batch number: 217, Losses: {'trf_textcat': 0.0002155290537757537}\n",
            "Batch number: 218, Losses: {'trf_textcat': 0.00021651670851952076}\n",
            "Batch number: 219, Losses: {'trf_textcat': 0.00021750517839791428}\n",
            "Batch number: 220, Losses: {'trf_textcat': 0.0002184929116992862}\n",
            "Batch number: 221, Losses: {'trf_textcat': 0.00021948061521470663}\n",
            "Batch number: 222, Losses: {'trf_textcat': 0.00022046988488000352}\n",
            "Batch number: 223, Losses: {'trf_textcat': 0.00022145855007238424}\n",
            "Batch number: 224, Losses: {'trf_textcat': 0.00022244736135235144}\n",
            "Batch number: 225, Losses: {'trf_textcat': 0.00022343569298755028}\n",
            "Batch number: 226, Losses: {'trf_textcat': 0.00022442333863637032}\n",
            "Batch number: 227, Losses: {'trf_textcat': 0.0002254115223649933}\n",
            "Batch number: 228, Losses: {'trf_textcat': 0.0002263995127123053}\n",
            "Batch number: 229, Losses: {'trf_textcat': 0.00022738790744369908}\n",
            "Batch number: 230, Losses: {'trf_textcat': 0.00022837728636204702}\n",
            "Batch number: 231, Losses: {'trf_textcat': 0.0002293664999797329}\n",
            "Batch number: 232, Losses: {'trf_textcat': 0.0002303548995996607}\n",
            "Batch number: 233, Losses: {'trf_textcat': 0.00023134446541916986}\n",
            "Batch number: 234, Losses: {'trf_textcat': 0.00023233246542986308}\n",
            "Batch number: 235, Losses: {'trf_textcat': 0.0002333208099116746}\n",
            "Batch number: 236, Losses: {'trf_textcat': 0.00023430854901107523}\n",
            "Batch number: 237, Losses: {'trf_textcat': 0.00023529717714154685}\n",
            "Batch number: 238, Losses: {'trf_textcat': 0.0002362839301213171}\n",
            "Batch number: 239, Losses: {'trf_textcat': 0.0002372719816321478}\n",
            "Batch number: 240, Losses: {'trf_textcat': 0.00024336359842891397}\n",
            "Iteration: 0, Losses: {'trf_textcat': 0.00024336359842891397}\n",
            "Batch number: 0, Losses: {'trf_textcat': 9.884205383059452e-07}\n",
            "Batch number: 1, Losses: {'trf_textcat': 1.9761497469517053e-06}\n",
            "Batch number: 2, Losses: {'trf_textcat': 2.9645314043591497e-06}\n",
            "Batch number: 3, Losses: {'trf_textcat': 3.951863050133397e-06}\n",
            "Batch number: 4, Losses: {'trf_textcat': 4.941031079397362e-06}\n",
            "Batch number: 5, Losses: {'trf_textcat': 5.929696726525435e-06}\n",
            "Batch number: 6, Losses: {'trf_textcat': 6.919040060893167e-06}\n",
            "Batch number: 7, Losses: {'trf_textcat': 7.908366683295753e-06}\n",
            "Batch number: 8, Losses: {'trf_textcat': 8.89569787432265e-06}\n",
            "Batch number: 9, Losses: {'trf_textcat': 9.884779501589946e-06}\n",
            "Batch number: 10, Losses: {'trf_textcat': 1.0873265068767068e-05}\n",
            "Batch number: 11, Losses: {'trf_textcat': 1.1861832831527863e-05}\n",
            "Batch number: 12, Losses: {'trf_textcat': 1.2848201890847122e-05}\n",
            "Batch number: 13, Losses: {'trf_textcat': 1.3836223388352664e-05}\n",
            "Batch number: 14, Losses: {'trf_textcat': 1.4824401660007425e-05}\n",
            "Batch number: 15, Losses: {'trf_textcat': 1.581210415224632e-05}\n",
            "Batch number: 16, Losses: {'trf_textcat': 1.6800433741082088e-05}\n",
            "Batch number: 17, Losses: {'trf_textcat': 1.7789776734389307e-05}\n",
            "Batch number: 18, Losses: {'trf_textcat': 1.877820091067406e-05}\n",
            "Batch number: 19, Losses: {'trf_textcat': 1.9766752188843384e-05}\n",
            "Batch number: 20, Losses: {'trf_textcat': 2.075593761219352e-05}\n",
            "Batch number: 21, Losses: {'trf_textcat': 2.1743959109699063e-05}\n",
            "Batch number: 22, Losses: {'trf_textcat': 2.2732315869689046e-05}\n",
            "Batch number: 23, Losses: {'trf_textcat': 2.3721071897853108e-05}\n",
            "Batch number: 24, Losses: {'trf_textcat': 2.470965318934759e-05}\n",
            "Batch number: 25, Losses: {'trf_textcat': 2.5697747560116113e-05}\n",
            "Batch number: 26, Losses: {'trf_textcat': 2.6686262003750016e-05}\n",
            "Batch number: 27, Losses: {'trf_textcat': 2.767396665603883e-05}\n",
            "Batch number: 28, Losses: {'trf_textcat': 2.8662844329119253e-05}\n",
            "Batch number: 29, Losses: {'trf_textcat': 2.9652036801053328e-05}\n",
            "Batch number: 30, Losses: {'trf_textcat': 3.0639633337159466e-05}\n",
            "Batch number: 31, Losses: {'trf_textcat': 3.162840312143089e-05}\n",
            "Batch number: 32, Losses: {'trf_textcat': 3.261691119860188e-05}\n",
            "Batch number: 33, Losses: {'trf_textcat': 3.36044440700789e-05}\n",
            "Batch number: 34, Losses: {'trf_textcat': 3.459282277162856e-05}\n",
            "Batch number: 35, Losses: {'trf_textcat': 3.5581949532570434e-05}\n",
            "Batch number: 36, Losses: {'trf_textcat': 3.65700105930955e-05}\n",
            "Batch number: 37, Losses: {'trf_textcat': 3.755898183044337e-05}\n",
            "Batch number: 38, Losses: {'trf_textcat': 3.854819669868448e-05}\n",
            "Batch number: 39, Losses: {'trf_textcat': 3.953681334678549e-05}\n",
            "Batch number: 40, Losses: {'trf_textcat': 4.052544875321473e-05}\n",
            "Batch number: 41, Losses: {'trf_textcat': 4.151422808718053e-05}\n",
            "Batch number: 42, Losses: {'trf_textcat': 4.2501273355810554e-05}\n",
            "Batch number: 43, Losses: {'trf_textcat': 4.348961397226958e-05}\n",
            "Batch number: 44, Losses: {'trf_textcat': 4.447865762813308e-05}\n",
            "Batch number: 45, Losses: {'trf_textcat': 4.546590457721322e-05}\n",
            "Batch number: 46, Losses: {'trf_textcat': 4.645499575417489e-05}\n",
            "Batch number: 47, Losses: {'trf_textcat': 4.7443066364394326e-05}\n",
            "Batch number: 48, Losses: {'trf_textcat': 4.8431149366479076e-05}\n",
            "Batch number: 49, Losses: {'trf_textcat': 4.9418620164942695e-05}\n",
            "Batch number: 50, Losses: {'trf_textcat': 5.04082063343958e-05}\n",
            "Batch number: 51, Losses: {'trf_textcat': 5.139678137311421e-05}\n",
            "Batch number: 52, Losses: {'trf_textcat': 5.2384782293302123e-05}\n",
            "Batch number: 53, Losses: {'trf_textcat': 5.3373601645034796e-05}\n",
            "Batch number: 54, Losses: {'trf_textcat': 5.4362247055905755e-05}\n",
            "Batch number: 55, Losses: {'trf_textcat': 5.5351362902911205e-05}\n",
            "Batch number: 56, Losses: {'trf_textcat': 5.633841840335663e-05}\n",
            "Batch number: 57, Losses: {'trf_textcat': 5.732641704980779e-05}\n",
            "Batch number: 58, Losses: {'trf_textcat': 5.831460521221743e-05}\n",
            "Batch number: 59, Losses: {'trf_textcat': 5.930367206019582e-05}\n",
            "Batch number: 60, Losses: {'trf_textcat': 6.029140627106244e-05}\n",
            "Batch number: 61, Losses: {'trf_textcat': 6.127966616986669e-05}\n",
            "Batch number: 62, Losses: {'trf_textcat': 6.226665527719888e-05}\n",
            "Batch number: 63, Losses: {'trf_textcat': 6.32544015388703e-05}\n",
            "Batch number: 64, Losses: {'trf_textcat': 6.42418029883629e-05}\n",
            "Batch number: 65, Losses: {'trf_textcat': 6.523029344407405e-05}\n",
            "Batch number: 66, Losses: {'trf_textcat': 6.621744046242384e-05}\n",
            "Batch number: 67, Losses: {'trf_textcat': 6.720712019614439e-05}\n",
            "Batch number: 68, Losses: {'trf_textcat': 6.81948706642288e-05}\n",
            "Batch number: 69, Losses: {'trf_textcat': 6.918292501723045e-05}\n",
            "Batch number: 70, Losses: {'trf_textcat': 7.017149061994132e-05}\n",
            "Batch number: 71, Losses: {'trf_textcat': 7.116011352081841e-05}\n",
            "Batch number: 72, Losses: {'trf_textcat': 7.214886795736675e-05}\n",
            "Batch number: 73, Losses: {'trf_textcat': 7.313649507523223e-05}\n",
            "Batch number: 74, Losses: {'trf_textcat': 7.412407637730212e-05}\n",
            "Batch number: 75, Losses: {'trf_textcat': 7.51134460870162e-05}\n",
            "Batch number: 76, Losses: {'trf_textcat': 7.610129682689148e-05}\n",
            "Batch number: 77, Losses: {'trf_textcat': 7.708872135481215e-05}\n",
            "Batch number: 78, Losses: {'trf_textcat': 7.807383553881664e-05}\n",
            "Batch number: 79, Losses: {'trf_textcat': 7.906246730726707e-05}\n",
            "Batch number: 80, Losses: {'trf_textcat': 8.004989922483219e-05}\n",
            "Batch number: 81, Losses: {'trf_textcat': 8.10382825875422e-05}\n",
            "Batch number: 82, Losses: {'trf_textcat': 8.202669209822488e-05}\n",
            "Batch number: 83, Losses: {'trf_textcat': 8.301472701077728e-05}\n",
            "Batch number: 84, Losses: {'trf_textcat': 8.400353669912874e-05}\n",
            "Batch number: 85, Losses: {'trf_textcat': 8.499281943841197e-05}\n",
            "Batch number: 86, Losses: {'trf_textcat': 8.597934595400147e-05}\n",
            "Batch number: 87, Losses: {'trf_textcat': 8.69665268510289e-05}\n",
            "Batch number: 88, Losses: {'trf_textcat': 8.795488145096897e-05}\n",
            "Batch number: 89, Losses: {'trf_textcat': 8.89440710807321e-05}\n",
            "Batch number: 90, Losses: {'trf_textcat': 8.993220910724631e-05}\n",
            "Batch number: 91, Losses: {'trf_textcat': 9.092124298604176e-05}\n",
            "Batch number: 92, Losses: {'trf_textcat': 9.190941932502028e-05}\n",
            "Batch number: 93, Losses: {'trf_textcat': 9.289749118579493e-05}\n",
            "Batch number: 94, Losses: {'trf_textcat': 9.388556884459831e-05}\n",
            "Batch number: 95, Losses: {'trf_textcat': 9.487341969816043e-05}\n",
            "Batch number: 96, Losses: {'trf_textcat': 9.586047974607936e-05}\n",
            "Batch number: 97, Losses: {'trf_textcat': 9.684938470400084e-05}\n",
            "Batch number: 98, Losses: {'trf_textcat': 9.783823520592705e-05}\n",
            "Batch number: 99, Losses: {'trf_textcat': 9.882727761123533e-05}\n",
            "Batch number: 100, Losses: {'trf_textcat': 9.981570860873035e-05}\n",
            "Batch number: 101, Losses: {'trf_textcat': 0.00010080392291911267}\n",
            "Batch number: 102, Losses: {'trf_textcat': 0.00010179176649671717}\n",
            "Batch number: 103, Losses: {'trf_textcat': 0.00010278077957082132}\n",
            "Batch number: 104, Losses: {'trf_textcat': 0.00010376994771377213}\n",
            "Batch number: 105, Losses: {'trf_textcat': 0.00010475836643308867}\n",
            "Batch number: 106, Losses: {'trf_textcat': 0.00010574615839686885}\n",
            "Batch number: 107, Losses: {'trf_textcat': 0.00010673486997347936}\n",
            "Batch number: 108, Losses: {'trf_textcat': 0.00010772247776458244}\n",
            "Batch number: 109, Losses: {'trf_textcat': 0.00010870960704778554}\n",
            "Batch number: 110, Losses: {'trf_textcat': 0.00010969926825055154}\n",
            "Batch number: 111, Losses: {'trf_textcat': 0.0001106865381643729}\n",
            "Batch number: 112, Losses: {'trf_textcat': 0.00011167521813604253}\n",
            "Batch number: 113, Losses: {'trf_textcat': 0.00011266273452292808}\n",
            "Batch number: 114, Losses: {'trf_textcat': 0.00011365154330178484}\n",
            "Batch number: 115, Losses: {'trf_textcat': 0.0001146400271636594}\n",
            "Batch number: 116, Losses: {'trf_textcat': 0.00011562656345631694}\n",
            "Batch number: 117, Losses: {'trf_textcat': 0.00011661472922241956}\n",
            "Batch number: 118, Losses: {'trf_textcat': 0.00011760219490497548}\n",
            "Batch number: 119, Losses: {'trf_textcat': 0.00011858956577270874}\n",
            "Batch number: 120, Losses: {'trf_textcat': 0.00011957848539623228}\n",
            "Batch number: 121, Losses: {'trf_textcat': 0.00012056730997755949}\n",
            "Batch number: 122, Losses: {'trf_textcat': 0.0001215546285493474}\n",
            "Batch number: 123, Losses: {'trf_textcat': 0.00012254199430117296}\n",
            "Batch number: 124, Losses: {'trf_textcat': 0.00012353144813914696}\n",
            "Batch number: 125, Losses: {'trf_textcat': 0.00012451838119886816}\n",
            "Batch number: 126, Losses: {'trf_textcat': 0.00012550741257655318}\n",
            "Batch number: 127, Losses: {'trf_textcat': 0.00012649667132791365}\n",
            "Batch number: 128, Losses: {'trf_textcat': 0.00012748538972573442}\n",
            "Batch number: 129, Losses: {'trf_textcat': 0.0001284733230022539}\n",
            "Batch number: 130, Losses: {'trf_textcat': 0.0001294621090437431}\n",
            "Batch number: 131, Losses: {'trf_textcat': 0.0001304506430415131}\n",
            "Batch number: 132, Losses: {'trf_textcat': 0.00013143876697085943}\n",
            "Batch number: 133, Losses: {'trf_textcat': 0.00013242723593975825}\n",
            "Batch number: 134, Losses: {'trf_textcat': 0.00013341554210910544}\n",
            "Batch number: 135, Losses: {'trf_textcat': 0.00013440454279134428}\n",
            "Batch number: 136, Losses: {'trf_textcat': 0.00013539243707327842}\n",
            "Batch number: 137, Losses: {'trf_textcat': 0.000136380394792468}\n",
            "Batch number: 138, Losses: {'trf_textcat': 0.00013736886171500373}\n",
            "Batch number: 139, Losses: {'trf_textcat': 0.0001383568594519602}\n",
            "Batch number: 140, Losses: {'trf_textcat': 0.00013934521575720282}\n",
            "Batch number: 141, Losses: {'trf_textcat': 0.00014033339186880767}\n",
            "Batch number: 142, Losses: {'trf_textcat': 0.00014132215096651635}\n",
            "Batch number: 143, Losses: {'trf_textcat': 0.00014231044337975618}\n",
            "Batch number: 144, Losses: {'trf_textcat': 0.00014329883435948432}\n",
            "Batch number: 145, Losses: {'trf_textcat': 0.0001442859879716707}\n",
            "Batch number: 146, Losses: {'trf_textcat': 0.00014527540974995645}\n",
            "Batch number: 147, Losses: {'trf_textcat': 0.00014626518657223642}\n",
            "Batch number: 148, Losses: {'trf_textcat': 0.0001472529230568398}\n",
            "Batch number: 149, Losses: {'trf_textcat': 0.00014824168567884044}\n",
            "Batch number: 150, Losses: {'trf_textcat': 0.00014923075298156618}\n",
            "Batch number: 151, Losses: {'trf_textcat': 0.0001502193639453253}\n",
            "Batch number: 152, Losses: {'trf_textcat': 0.00015120714181193762}\n",
            "Batch number: 153, Losses: {'trf_textcat': 0.00015219514705222537}\n",
            "Batch number: 154, Losses: {'trf_textcat': 0.00015318457917601336}\n",
            "Batch number: 155, Losses: {'trf_textcat': 0.00015417314273236116}\n",
            "Batch number: 156, Losses: {'trf_textcat': 0.00015516091900735773}\n",
            "Batch number: 157, Losses: {'trf_textcat': 0.00015614855726653332}\n",
            "Batch number: 158, Losses: {'trf_textcat': 0.00015713719415089145}\n",
            "Batch number: 159, Losses: {'trf_textcat': 0.00015812608955911855}\n",
            "Batch number: 160, Losses: {'trf_textcat': 0.0001591143898167502}\n",
            "Batch number: 161, Losses: {'trf_textcat': 0.0001601021231181221}\n",
            "Batch number: 162, Losses: {'trf_textcat': 0.00016109035504996427}\n",
            "Batch number: 163, Losses: {'trf_textcat': 0.00016207830367420684}\n",
            "Batch number: 164, Losses: {'trf_textcat': 0.00016306721386172285}\n",
            "Batch number: 165, Losses: {'trf_textcat': 0.0001640547552597127}\n",
            "Batch number: 166, Losses: {'trf_textcat': 0.0001650425479056139}\n",
            "Batch number: 167, Losses: {'trf_textcat': 0.00016603176618446014}\n",
            "Batch number: 168, Losses: {'trf_textcat': 0.00016702015807368298}\n",
            "Batch number: 169, Losses: {'trf_textcat': 0.00016800791229343304}\n",
            "Batch number: 170, Losses: {'trf_textcat': 0.0001689966668436682}\n",
            "Batch number: 171, Losses: {'trf_textcat': 0.0001699853150967101}\n",
            "Batch number: 172, Losses: {'trf_textcat': 0.0001709736450266064}\n",
            "Batch number: 173, Losses: {'trf_textcat': 0.00017196081432757637}\n",
            "Batch number: 174, Losses: {'trf_textcat': 0.0001729490554680524}\n",
            "Batch number: 175, Losses: {'trf_textcat': 0.00017393616838035086}\n",
            "Batch number: 176, Losses: {'trf_textcat': 0.00017492468157342955}\n",
            "Batch number: 177, Losses: {'trf_textcat': 0.00017591281437034922}\n",
            "Batch number: 178, Losses: {'trf_textcat': 0.00017690050196961238}\n",
            "Batch number: 179, Losses: {'trf_textcat': 0.0001778877536935397}\n",
            "Batch number: 180, Losses: {'trf_textcat': 0.00017887717069697828}\n",
            "Batch number: 181, Losses: {'trf_textcat': 0.00017986482760079525}\n",
            "Batch number: 182, Losses: {'trf_textcat': 0.00018085346982843475}\n",
            "Batch number: 183, Losses: {'trf_textcat': 0.0001818399672401938}\n",
            "Batch number: 184, Losses: {'trf_textcat': 0.00018282886856013647}\n",
            "Batch number: 185, Losses: {'trf_textcat': 0.0001838165039771411}\n",
            "Batch number: 186, Losses: {'trf_textcat': 0.00018480405208265438}\n",
            "Batch number: 187, Losses: {'trf_textcat': 0.00018579201366719644}\n",
            "Batch number: 188, Losses: {'trf_textcat': 0.00018678015135265014}\n",
            "Batch number: 189, Losses: {'trf_textcat': 0.00018776782098939293}\n",
            "Batch number: 190, Losses: {'trf_textcat': 0.00018875613238833466}\n",
            "Batch number: 191, Losses: {'trf_textcat': 0.00018974564170548547}\n",
            "Batch number: 192, Losses: {'trf_textcat': 0.00019073332873631443}\n",
            "Batch number: 193, Losses: {'trf_textcat': 0.0001917210950068693}\n",
            "Batch number: 194, Losses: {'trf_textcat': 0.0001927080473933529}\n",
            "Batch number: 195, Losses: {'trf_textcat': 0.00019369741801256168}\n",
            "Batch number: 196, Losses: {'trf_textcat': 0.0001946848707348181}\n",
            "Batch number: 197, Losses: {'trf_textcat': 0.00019567291485600435}\n",
            "Batch number: 198, Losses: {'trf_textcat': 0.0001966602627589964}\n",
            "Batch number: 199, Losses: {'trf_textcat': 0.00019764950661738112}\n",
            "Batch number: 200, Losses: {'trf_textcat': 0.0001986380417520195}\n",
            "Batch number: 201, Losses: {'trf_textcat': 0.00019962632700298855}\n",
            "Batch number: 202, Losses: {'trf_textcat': 0.00020061387772329908}\n",
            "Batch number: 203, Losses: {'trf_textcat': 0.00020160342216968274}\n",
            "Batch number: 204, Losses: {'trf_textcat': 0.0002025903135063345}\n",
            "Batch number: 205, Losses: {'trf_textcat': 0.0002035788312468867}\n",
            "Batch number: 206, Losses: {'trf_textcat': 0.00020456710740290873}\n",
            "Batch number: 207, Losses: {'trf_textcat': 0.00020555466778660048}\n",
            "Batch number: 208, Losses: {'trf_textcat': 0.00020654213187754067}\n",
            "Batch number: 209, Losses: {'trf_textcat': 0.00020752936507051345}\n",
            "Batch number: 210, Losses: {'trf_textcat': 0.00020851798217336182}\n",
            "Batch number: 211, Losses: {'trf_textcat': 0.00020950601026470395}\n",
            "Batch number: 212, Losses: {'trf_textcat': 0.00021049364852387953}\n",
            "Batch number: 213, Losses: {'trf_textcat': 0.00021148232872292283}\n",
            "Batch number: 214, Losses: {'trf_textcat': 0.00021247118172595947}\n",
            "Batch number: 215, Losses: {'trf_textcat': 0.00021345952461615525}\n",
            "Batch number: 216, Losses: {'trf_textcat': 0.00021444634910494642}\n",
            "Batch number: 217, Losses: {'trf_textcat': 0.00021543391358136432}\n",
            "Batch number: 218, Losses: {'trf_textcat': 0.00021642281660660956}\n",
            "Batch number: 219, Losses: {'trf_textcat': 0.00021741111243045452}\n",
            "Batch number: 220, Losses: {'trf_textcat': 0.0002183988983688323}\n",
            "Batch number: 221, Losses: {'trf_textcat': 0.0002193883166228261}\n",
            "Batch number: 222, Losses: {'trf_textcat': 0.00022037727489987446}\n",
            "Batch number: 223, Losses: {'trf_textcat': 0.00022136396944461012}\n",
            "Batch number: 224, Losses: {'trf_textcat': 0.00022235206779441796}\n",
            "Batch number: 225, Losses: {'trf_textcat': 0.00022333990159495443}\n",
            "Batch number: 226, Losses: {'trf_textcat': 0.00022432726302668016}\n",
            "Batch number: 227, Losses: {'trf_textcat': 0.00022531444744799956}\n",
            "Batch number: 228, Losses: {'trf_textcat': 0.00022630414366631157}\n",
            "Batch number: 229, Losses: {'trf_textcat': 0.00022729264230747503}\n",
            "Batch number: 230, Losses: {'trf_textcat': 0.00022828133728580724}\n",
            "Batch number: 231, Losses: {'trf_textcat': 0.0002292695860433014}\n",
            "Batch number: 232, Losses: {'trf_textcat': 0.0002302569477024008}\n",
            "Batch number: 233, Losses: {'trf_textcat': 0.0002312452439809931}\n",
            "Batch number: 234, Losses: {'trf_textcat': 0.0002322337219311521}\n",
            "Batch number: 235, Losses: {'trf_textcat': 0.00023322141885273595}\n",
            "Batch number: 236, Losses: {'trf_textcat': 0.00023421000992129848}\n",
            "Batch number: 237, Losses: {'trf_textcat': 0.0002351984120423367}\n",
            "Batch number: 238, Losses: {'trf_textcat': 0.00023618615841769497}\n",
            "Batch number: 239, Losses: {'trf_textcat': 0.00023717366764230974}\n",
            "Batch number: 240, Losses: {'trf_textcat': 0.00024326363688942365}\n",
            "Iteration: 1, Losses: {'trf_textcat': 0.00024326363688942365}\n",
            "Batch number: 0, Losses: {'trf_textcat': 9.880885727397981e-07}\n",
            "Batch number: 1, Losses: {'trf_textcat': 1.9747395754166064e-06}\n",
            "Batch number: 2, Losses: {'trf_textcat': 2.9636440785907325e-06}\n",
            "Batch number: 3, Losses: {'trf_textcat': 3.951559733650356e-06}\n",
            "Batch number: 4, Losses: {'trf_textcat': 4.9405703066440765e-06}\n",
            "Batch number: 5, Losses: {'trf_textcat': 5.928100108576473e-06}\n",
            "Batch number: 6, Losses: {'trf_textcat': 6.915884796399041e-06}\n",
            "Batch number: 7, Losses: {'trf_textcat': 7.90508602221962e-06}\n",
            "Batch number: 8, Losses: {'trf_textcat': 8.892926985026861e-06}\n",
            "Batch number: 9, Losses: {'trf_textcat': 9.881541245704284e-06}\n",
            "Batch number: 10, Losses: {'trf_textcat': 1.0869835364246683e-05}\n",
            "Batch number: 11, Losses: {'trf_textcat': 1.1859032952088455e-05}\n",
            "Batch number: 12, Losses: {'trf_textcat': 1.2846599474869436e-05}\n",
            "Batch number: 13, Losses: {'trf_textcat': 1.3835118579663686e-05}\n",
            "Batch number: 14, Losses: {'trf_textcat': 1.4824001141278131e-05}\n",
            "Batch number: 15, Losses: {'trf_textcat': 1.5812486140021065e-05}\n",
            "Batch number: 16, Losses: {'trf_textcat': 1.6800033563413308e-05}\n",
            "Batch number: 17, Losses: {'trf_textcat': 1.7787868841878662e-05}\n",
            "Batch number: 18, Losses: {'trf_textcat': 1.8776860315483646e-05}\n",
            "Batch number: 19, Losses: {'trf_textcat': 1.9764983335335273e-05}\n",
            "Batch number: 20, Losses: {'trf_textcat': 2.0753621129188105e-05}\n",
            "Batch number: 21, Losses: {'trf_textcat': 2.1742088733844867e-05}\n",
            "Batch number: 22, Losses: {'trf_textcat': 2.2729984721081564e-05}\n",
            "Batch number: 23, Losses: {'trf_textcat': 2.371722371208307e-05}\n",
            "Batch number: 24, Losses: {'trf_textcat': 2.47041939474002e-05}\n",
            "Batch number: 25, Losses: {'trf_textcat': 2.5692648023323272e-05}\n",
            "Batch number: 26, Losses: {'trf_textcat': 2.6680863243200292e-05}\n",
            "Batch number: 27, Losses: {'trf_textcat': 2.766980617252557e-05}\n",
            "Batch number: 28, Losses: {'trf_textcat': 2.8659633358074643e-05}\n",
            "Batch number: 29, Losses: {'trf_textcat': 2.9648098347934138e-05}\n",
            "Batch number: 30, Losses: {'trf_textcat': 3.0636911446890736e-05}\n",
            "Batch number: 31, Losses: {'trf_textcat': 3.162448172133736e-05}\n",
            "Batch number: 32, Losses: {'trf_textcat': 3.2613655207569536e-05}\n",
            "Batch number: 33, Losses: {'trf_textcat': 3.360085088388587e-05}\n",
            "Batch number: 34, Losses: {'trf_textcat': 3.458842718373489e-05}\n",
            "Batch number: 35, Losses: {'trf_textcat': 3.5576595337261097e-05}\n",
            "Batch number: 36, Losses: {'trf_textcat': 3.656458727618883e-05}\n",
            "Batch number: 37, Losses: {'trf_textcat': 3.7552076719293837e-05}\n",
            "Batch number: 38, Losses: {'trf_textcat': 3.8540541936527006e-05}\n",
            "Batch number: 39, Losses: {'trf_textcat': 3.9529141986349714e-05}\n",
            "Batch number: 40, Losses: {'trf_textcat': 4.051808639360388e-05}\n",
            "Batch number: 41, Losses: {'trf_textcat': 4.150629320065491e-05}\n",
            "Batch number: 42, Losses: {'trf_textcat': 4.2493556634326524e-05}\n",
            "Batch number: 43, Losses: {'trf_textcat': 4.348161769485159e-05}\n",
            "Batch number: 44, Losses: {'trf_textcat': 4.44696270278655e-05}\n",
            "Batch number: 45, Losses: {'trf_textcat': 4.545761169083562e-05}\n",
            "Batch number: 46, Losses: {'trf_textcat': 4.6445961402241664e-05}\n",
            "Batch number: 47, Losses: {'trf_textcat': 4.743474516999413e-05}\n",
            "Batch number: 48, Losses: {'trf_textcat': 4.8423996076962794e-05}\n",
            "Batch number: 49, Losses: {'trf_textcat': 4.941183578921482e-05}\n",
            "Batch number: 50, Losses: {'trf_textcat': 5.0399583756188804e-05}\n",
            "Batch number: 51, Losses: {'trf_textcat': 5.1387806934144464e-05}\n",
            "Batch number: 52, Losses: {'trf_textcat': 5.237621212472732e-05}\n",
            "Batch number: 53, Losses: {'trf_textcat': 5.336462629657035e-05}\n",
            "Batch number: 54, Losses: {'trf_textcat': 5.4353550808627915e-05}\n",
            "Batch number: 55, Losses: {'trf_textcat': 5.53411960027006e-05}\n",
            "Batch number: 56, Losses: {'trf_textcat': 5.632933971355669e-05}\n",
            "Batch number: 57, Losses: {'trf_textcat': 5.731730993829842e-05}\n",
            "Batch number: 58, Losses: {'trf_textcat': 5.830523184613412e-05}\n",
            "Batch number: 59, Losses: {'trf_textcat': 5.9294400330145436e-05}\n",
            "Batch number: 60, Losses: {'trf_textcat': 6.0283296761554084e-05}\n",
            "Batch number: 61, Losses: {'trf_textcat': 6.127062977157038e-05}\n",
            "Batch number: 62, Losses: {'trf_textcat': 6.225837648798915e-05}\n",
            "Batch number: 63, Losses: {'trf_textcat': 6.324636217414081e-05}\n",
            "Batch number: 64, Losses: {'trf_textcat': 6.423434103908221e-05}\n",
            "Batch number: 65, Losses: {'trf_textcat': 6.522162505007145e-05}\n",
            "Batch number: 66, Losses: {'trf_textcat': 6.6209724309374e-05}\n",
            "Batch number: 67, Losses: {'trf_textcat': 6.719790587794705e-05}\n",
            "Batch number: 68, Losses: {'trf_textcat': 6.818542124165106e-05}\n",
            "Batch number: 69, Losses: {'trf_textcat': 6.917362873082311e-05}\n",
            "Batch number: 70, Losses: {'trf_textcat': 7.016126392045408e-05}\n",
            "Batch number: 71, Losses: {'trf_textcat': 7.114951313269557e-05}\n",
            "Batch number: 72, Losses: {'trf_textcat': 7.213830087948736e-05}\n",
            "Batch number: 73, Losses: {'trf_textcat': 7.312561876915424e-05}\n",
            "Batch number: 74, Losses: {'trf_textcat': 7.411305819005065e-05}\n",
            "Batch number: 75, Losses: {'trf_textcat': 7.510135708344023e-05}\n",
            "Batch number: 76, Losses: {'trf_textcat': 7.608910937051405e-05}\n",
            "Batch number: 77, Losses: {'trf_textcat': 7.707705867687764e-05}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yf9OvL_hea-",
        "colab_type": "code",
        "outputId": "c328b69c-ed50-46ae-b58d-640389fabe00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "a = nlp(\"Parliament passes Zainab Alert Bill for recovery of missing children - Samaa News\")\n",
        "a.cats\n",
        "for key, value in sorted(a.cats.items(), key=lambda item: item[1]):\n",
        "    print(\"%s: %s\" % (key, value))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c890f14a3eb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Parliament passes Zainab Alert Bill for recovery of missing children - Samaa News\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nlp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63Y6ESVLJrZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy_transformers import TransformersLanguage, TransformersWordPiecer, TransformersTok2Vec\n",
        "\n",
        "name = \"bert-base-uncased\"\n",
        "nlp = TransformersLanguage(trf_name=name, meta={\"lang\": \"en\"})\n",
        "nlp.add_pipe(nlp.create_pipe(\"sentencizer\"))\n",
        "nlp.add_pipe(TransformersWordPiecer.from_pretrained(nlp.vocab, name))\n",
        "nlp.add_pipe(TransformersTok2Vec.from_pretrained(nlp.vocab, name))\n",
        "print(nlp.pipe_names)  # ['sentencizer', 'trf_wordpiecer', 'trf_tok2vec']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW37K6y5Kbrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "textnews = nlp.create_pipe(\"trf_textcat\", config={\"exclusive_classes\": True})\n",
        "for label in list_of_sites:\n",
        "    textnews.add_label(label)\n",
        "nlp.add_pipe(textnews)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}