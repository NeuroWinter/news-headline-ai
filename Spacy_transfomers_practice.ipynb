{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spacy-transfomers-practice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeuroWinter/news-headline-ai/blob/master/Spacy_transfomers_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOucPcydcmNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U spacy[cuda100]\n",
        "!pip install spacy-transformers\n",
        "!python3 -m spacy download en_trf_distilbertbaseuncased_lg\n",
        "!pip install torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJHwnL15E3i1",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUIq-IpqE-w4",
        "colab_type": "code",
        "outputId": "5c6f5d54-a4d4-4ac9-d61e-7c5fcdefb67d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "# REMEBER TO UPLOAD THIS!\n",
        "input_file = 'news_headlines.csv'\n",
        "\n",
        "TRAIN_DATA = []\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "list_of_sites = list(df['news_site'].unique())\n",
        "\n",
        "for row in df.iterrows():\n",
        "    row_headline = row[1][2].strip()\n",
        "    row_site     = row[1][1]\n",
        "    if row_headline:\n",
        "        # Add all the sites to the dict\n",
        "        row_cat            = {site: 0.0 for site in list_of_sites}\n",
        "        row_cat[row_site] += 1.0\n",
        "        TRAIN_DATA.append((row_headline.strip(), {\"cats\": row_cat}))\n",
        "print(TRAIN_DATA[0])\n",
        "df = None"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Experts say adapting to climate change can pay off manifold', {'cats': {'ABC - Tech': 1.0, 'ABC - Top Stories': 0.0, 'ABC - US': 0.0, 'ABC - World': 0.0, 'Al Jazeera': 0.0, 'AllAfrica News - Mozambique': 0.0, 'ARRL': 0.0, 'Ars Technica - all features': 0.0, 'Ars Technica - all news': 0.0, 'Axios - Business': 0.0, 'Axios - Energy': 0.0, 'Axios - Future': 0.0, 'Axios - Health Care': 0.0, 'Axios - Politics': 0.0, 'Axios - Science': 0.0, 'Axios - Technology': 0.0, 'Axios - Top': 0.0, 'Axios - World': 0.0, 'Bandladesh - bdnews24.com': 0.0, 'Bangkok Post - Lifestyle': 0.0, 'Bangkok Post - Most Recent': 0.0, 'Bangkok Post - Top Stories': 0.0, 'Bangkok Post - Travel': 0.0, 'BBC': 0.0, 'BBC - Africa': 0.0, 'BBC - Asia': 0.0, 'BBC - England': 0.0, 'BBC - Europe': 0.0, 'BBC - Latin America': 0.0, 'BBC - Middle East': 0.0, 'BBC - Northern Ireland': 0.0, 'BBC - Scotland': 0.0, 'BBC - UK': 0.0, 'BBC - US & Canada': 0.0, 'BBC - Wales': 0.0, 'BBC - World': 0.0, 'Breitbart \"News\"': 0.0, 'Buzzfeed - US News': 0.0, 'CanLii - Regulations': 0.0, 'CanLii - Supreme Court of Canada': 0.0, 'Caracas Chronicles - all': 0.0, 'CBC - Aboriginal': 0.0, 'CBC - Canada': 0.0, 'CBC - Politics': 0.0, 'CBC - Top Stories': 0.0, 'CBC - World': 0.0, 'CBS - 48 Hours': 0.0, 'CBS - 60 Minutes': 0.0, 'CBS - Politics': 0.0, 'CBS - Primary Source': 0.0, 'CBS - SciTech': 0.0, 'CBS - Strange': 0.0, 'CBS - TechTalk': 0.0, 'CBS - US': 0.0, 'CBS - World': 0.0, 'ChinaDaily - HK News': 0.0, 'ChinaDaily - News': 0.0, 'Civil.ge': 0.0, 'CNBC - Earnings Central': 0.0, 'CNBC - Economy': 0.0, 'CNBC - Energy': 0.0, 'CNBC - Investing': 0.0, 'CNBC - News': 0.0, 'CNBC - News Releases': 0.0, 'CNBC - Politics': 0.0, 'CNBC - Tech/Business': 0.0, 'CNET - News': 0.0, 'CNN - Politics': 0.0, 'CNN - Top Stories': 0.0, 'CTV News - Canada': 0.0, 'CTV News - Montreal Latest': 0.0, 'CTV News - Politics': 0.0, 'CTV News - Top Stories': 0.0, 'CTV News - World': 0.0, 'Daily Kos': 0.0, 'Daily Maverick': 0.0, 'Daily Post Nigeria - all': 0.0, 'Der Spiegel': 0.0, 'Der Spiegel - auf Deutsch': 0.0, 'Der Spiegel - Business News': 0.0, 'Der Spiegel - European News': 0.0, 'Der Spiegel - Germany News': 0.0, 'Der Spiegel - World News': 0.0, 'Der Spiegel - Zeitgeist': 0.0, 'Drudge Report': 0.0, 'DSL Reports': 0.0, 'Ed Felten - Freedom to Tinker': 0.0, 'EFF Updates': 0.0, 'en.publika.md': 0.0, 'eNCA - Top Stories': 0.0, 'EU vs DISINFORMATION': 0.0, 'FactCheck': 0.0, 'FactCheckNI': 0.0, 'Financial Times - Asia': 0.0, 'Financial Times - Europe': 0.0, 'Financial Times - India': 0.0, 'Financial Times - Middle East': 0.0, 'Financial Times - UK': 0.0, 'Financial Times - US': 0.0, 'FiveThirtyEight - All': 0.0, 'FiveThirtyEight - Nate Silver': 0.0, 'FoxNews': 0.0, 'FoxNews - Politics': 0.0, 'france24': 0.0, 'freenode': 0.0, 'Futura Sciences': 0.0, 'GlobalNews.ca': 0.0, 'GlobalNews.ca - Canada': 0.0, 'GlobalNews.ca - Politics': 0.0, 'GlobalNews.ca - World': 0.0, 'Goo2019-11-20 10:19:18\\tâ„¹ \\tTopic for ##news is \"[world': 0.0, 'Google News - \"Catalonia\"': 0.0, 'Google News - \"Iran\"': 0.0, 'Google News - \"North Korea\"': 0.0, 'Google News - \"Palestine\"': 0.0, 'Google News - \"Palestinian\"': 0.0, 'Google News - \"Russia\"': 0.0, 'Google News - \"spain\"': 0.0, 'Google News - \"Syria\"': 0.0, 'Google News - \"Turkey\"': 0.0, 'Google News - Canada': 0.0, 'Google News - Canada - Top Stories': 0.0, 'Google News - Health': 0.0, 'Google News - India': 0.0, 'Google News - Ireland': 0.0, 'Google News - Israel': 0.0, 'Google News - Malaysia': 0.0, 'Google News - Pakistan': 0.0, 'Google News - Philippines': 0.0, 'Google News - Science': 0.0, 'Google News - Singapore': 0.0, 'Google News - South Africa': 0.0, 'Google News - Technology': 0.0, 'Google News - Uganda': 0.0, 'Google News - UK': 0.0, 'Google News - US': 0.0, 'Google News - US Business': 0.0, 'Google News - Venezuela': 0.0, 'Google News - World': 0.0, 'Google News - Zimbabwe': 0.0, 'Gossip Cop': 0.0, 'Haaretz - All Headlines': 0.0, 'Haaretz - Israel News': 0.0, 'Haaretz - WorldNews': 0.0, 'Hacker News': 0.0, 'Hoax Slayer': 0.0, 'HRC': 0.0, 'Huffington Post - Business News': 0.0, 'Huffington Post - Education News': 0.0, 'Huffington Post - Money': 0.0, 'Huffington Post - Politics': 0.0, 'Huffington Post - Religion': 0.0, 'Huffington Post - Weird News': 0.0, 'Independent - Business': 0.0, 'Independent - Education': 0.0, 'Independent - Media': 0.0, 'Independent - Money': 0.0, 'Independent - News': 0.0, 'Independent - Science': 0.0, 'Independent - UK': 0.0, 'Independent - World': 0.0, 'infowars': 0.0, 'ISC': 0.0, 'Japan Today': 0.0, 'Journal du hacker': 0.0, 'JPost - Arab Israeli Conflict': 0.0, 'JPost - BDS Movement': 0.0, 'JPost - Breaking News': 0.0, 'JPost - Gaza News': 0.0, 'Laotian Times - all': 0.0, 'Lead Stories': 0.0, 'LGBTQ Nation - all': 0.0, 'Mail & Guardian': 0.0, 'Media Bias/Fact Check': 0.0, 'Metabunk': 0.0, 'Metro - The Guardian Nigeria': 0.0, 'MetroNews - Canada': 0.0, 'MetroNews - Toronto': 0.0, 'MetroNews - World': 0.0, 'Mexico News Daily': 0.0, 'MotherJones - all': 0.0, 'MSNBC - Latest Headlines': 0.0, 'NBC - Politics': 0.0, 'NBC - Top Stories': 0.0, 'NBC - US': 0.0, 'Nepali Times - all': 0.0, 'New Statesman': 0.0, 'New Statesmen - Politics': 0.0, 'News24 - Africa': 0.0, 'News24 - South Africa': 0.0, 'News24 - Top Stories': 0.0, 'News24 - World': 0.0, 'Newsy - All Videos': 0.0, 'Nikkei Asian Review': 0.0, 'North Korea News.org - all': 0.0, 'North Korean Times - Latest': 0.0, 'Novinite (Bulgarian)': 0.0, 'NPR - Arts': 0.0, 'NPR - Business': 0.0, 'NPR - Health & Science': 0.0, 'NPR - Middle East': 0.0, 'NPR - News': 0.0, 'NPR - Politics': 0.0, 'NPR - Research News': 0.0, 'NPR - Space': 0.0, 'NPR - U.S. News': 0.0, 'NPR - World News': 0.0, 'NY Post': 0.0, 'NYT - Africa': 0.0, 'NYT - Americas': 0.0, 'NYT - Asia Pacific': 0.0, 'NYT - Business': 0.0, 'NYT - Europe': 0.0, 'NYT - Middle East': 0.0, 'NYT - Science': 0.0, 'NYT - Technology': 0.0, 'NYT - US': 0.0, 'NYT - US Politics': 0.0, 'NYT - Wire': 0.0, 'NYT - World News': 0.0, 'OANN - all': 0.0, 'OANN - Business': 0.0, 'OANN - Economy': 0.0, 'OANN - Money': 0.0, 'OANN - Tech': 0.0, 'OANN - Top News': 0.0, 'OANN - World': 0.0, 'PBS - NewsHour The Latest': 0.0, 'Peruvian Times': 0.0, 'Phoronix': 0.0, 'Politico - Congress': 0.0, 'Politico - Defense': 0.0, 'Politico - Economy': 0.0, 'Politico - Energy & Environment': 0.0, 'Politico - Health Care': 0.0, 'Politico - Picks': 0.0, 'Politico - Politics': 0.0, 'Politifact - Articles': 0.0, 'Politifact - Statements': 0.0, 'ProPublica - Main': 0.0, 'pulse.ng - Local': 0.0, 'Radio-Canada Nouvelles': 0.0, 'Rasmussen Reports': 0.0, 'Raw Story': 0.0, 'Real Clear Poltics': 0.0, 'Reason.com - Articles': 0.0, 'Reddit - /r/Europe': 0.0, 'Reddit - /r/netsec': 0.0, 'Reddit - /r/news': 0.0, 'Reddit - /r/politics': 0.0, 'Reddit - /r/TrueReddit': 0.0, 'Reddit - /r/UpliftingNews': 0.0, 'Reddit - /r/WorldNews - New': 0.0, 'Reddit - Russia Lago': 0.0, 'Reuters - Arts': 0.0, 'Reuters - Business': 0.0, 'Reuters - Company News': 0.0, 'Reuters - Entertainment': 0.0, 'Reuters - Environment': 0.0, 'Reuters - Health News': 0.0, 'Reuters - Lifestyle': 0.0, 'Reuters - Money': 0.0, 'Reuters - Most Watched Video': 0.0, 'Reuters - Oddly Enough': 0.0, 'Reuters - People': 0.0, 'Reuters - Pictures': 0.0, 'Reuters - Politics': 0.0, 'Reuters - Politics Video': 0.0, 'Reuters - Science': 0.0, 'Reuters - Sports': 0.0, 'Reuters - Technology': 0.0, 'Reuters - Top News': 0.0, 'Reuters - Top News Video': 0.0, 'Reuters - US News': 0.0, 'Reuters - World': 0.0, 'Reuters - World News Video': 0.0, 'RightWingWatch': 0.0, 'Rio Times - All': 0.0, 'RollCall - All': 0.0, 'RollCall - Heard on the Hill': 0.0, 'RollCall - News without Opinion': 0.0, 'RollCall - Opinion/Analysis': 0.0, 'RollCall - Policy': 0.0, 'RollCall - Rothenblog': 0.0, 'Romania Insider - all': 0.0, 'RT': 0.0, 'SABC News': 0.0, 'Science Daily - all': 0.0, 'SCOTUSblog': 0.0, 'Sky News': 0.0, 'Sky News - Business': 0.0, 'Sky News - Politics': 0.0, 'Sky News - Strange News': 0.0, 'Sky News - Technology': 0.0, 'Sky News - UK': 0.0, 'Sky News - US': 0.0, 'Sky News - World': 0.0, 'Slate - Main': 0.0, 'Slate - Politics': 0.0, 'Slate - Science': 0.0, 'Smithsonian Science': 0.0, 'Snopes': 0.0, 'South China Morning Post - (China) Diplomacy & Defense': 0.0, 'South China Morning Post - (China) Economy': 0.0, 'South China Morning Post - (China) Money & Wealth': 0.0, 'South China Morning Post - (China) Policies & Politics': 0.0, 'South China Morning Post - (China) Society': 0.0, 'South China Morning Post - (HK) Economy': 0.0, 'South China Morning Post - (HK) Law & Crime': 0.0, 'South China Morning Post - (HK) Politics': 0.0, 'South China Morning Post - Asia': 0.0, 'South China Morning Post - China': 0.0, 'South China Morning Post - Hong Kong': 0.0, 'South China Morning Post - News': 0.0, 'South China Morning Post - World': 0.0, 'South China MP - (Business) China Economy': 0.0, 'South China MP - Africa': 0.0, 'South China MP - Americas': 0.0, 'South China MP - Arts & Entertainment': 0.0, 'South China MP - Australasia': 0.0, 'South China MP - Culture': 0.0, 'South China MP - East Asia': 0.0, 'South China MP - Europe': 0.0, 'South China MP - Film & TV': 0.0, 'South China MP - Life': 0.0, 'South China MP - Middle East': 0.0, 'South China MP - Music': 0.0, 'South China MP - Property HK / China': 0.0, 'South China MP - Russia & Central Asia': 0.0, 'South China MP - Southeast Asia': 0.0, 'South China MP - This Week in Asia': 0.0, 'South China MP - TWIA Business': 0.0, 'South China MP - TWIA Opinion': 0.0, 'South China MP - TWIA Politics': 0.0, 'South China MP - USA': 0.0, 'SowetanLIVE': 0.0, 'SRN News': 0.0, 'SWI - Top News': 0.0, 'Sydney Anglicans - All News': 0.0, 'Sydney Morning Herald - Business': 0.0, 'Sydney Morning Herald - National': 0.0, 'Sydney Morning Herald - Technology': 0.0, 'Sydney Morning Herald - Top Stories': 0.0, 'Sydney Morning Herald - World': 0.0, 'Syrian Arab News Agency - all': 0.0, 'Taipei Times - all': 0.0, 'Taipei Times - Bilingual': 0.0, 'Taipei Times - Local News': 0.0, 'Taipei Times - World': 0.0, 'Taiwan Today - Top News': 0.0, 'techdirt': 0.0, 'Telegraph - Business': 0.0, 'Telegraph - Latest News': 0.0, 'Telegraph - News': 0.0, 'Telegraph - Politics': 0.0, 'Telegraph - Science': 0.0, 'Telegraph - Technology': 0.0, 'Thai PBS World': 0.0, 'Thailand News - Breaking': 0.0, 'The Atlantic - all': 0.0, 'The Atlantic - Global': 0.0, 'The Atlantic - Politics': 0.0, 'The Bali Times - all': 0.0, 'The Baltic Times - all': 0.0, 'The Citizen': 0.0, 'The Costa Rica News': 0.0, 'The Daily Caller - all': 0.0, 'The Gateway Pundit': 0.0, 'The Guardian - UK': 0.0, 'The Guardian - US': 0.0, 'The Hill - Administration': 0.0, 'The Hill - All News': 0.0, 'The Hill - Campaign': 0.0, 'The Hill - House': 0.0, 'The Hill - Senate': 0.0, 'The Himalayan Times - all': 0.0, 'The Intercept': 0.0, 'The Krakow Post - all': 0.0, 'The Local (Germany)': 0.0, 'The Local (Spain)': 0.0, 'The Moscow Times - News': 0.0, 'The Moscow Times - Opinion': 0.0, 'The Nation': 0.0, 'The Real News Network': 0.0, 'The Romania Journal - all': 0.0, 'The Slovak Spectator': 0.0, 'The Slovak Spectator - title': 0.0, 'The Sofia Globe (Bulgaria)': 0.0, 'The Standard (HK) - Latest News': 0.0, 'The Tico Times - Costa Rica News': 0.0, 'TheJournal': 0.0, 'Time - Blog: Politics, Swampland': 0.0, 'Time - Business': 0.0, 'Time - Health': 0.0, 'Time - Newsfeed': 0.0, 'Time - Science': 0.0, 'Time - Tech': 0.0, 'Time - Top Stories': 0.0, 'Time - World': 0.0, 'Times Colonist - All': 0.0, 'Times Colonist - B.C.': 0.0, 'Times Colonist - Business': 0.0, 'Times Colonist - News': 0.0, 'Times of India - China': 0.0, 'Times of India - Education': 0.0, 'Times of India - Environment': 0.0, 'Times of India - Europe': 0.0, 'Times of India - India': 0.0, 'Times of India - Mad, Mad World': 0.0, 'Times of India - Middle East': 0.0, 'Times of India - News (Video)': 0.0, 'Times of India - NRI': 0.0, 'Times of India - South Asia': 0.0, 'Times of India - Top Stories': 0.0, 'Times of India - UK': 0.0, 'Times of India - US': 0.0, 'Times of India - World': 0.0, 'Tonga Broadcasting': 0.0, 'TorrentFreak': 0.0, 'TownHall - Latest Breaking News': 0.0, 'TownHall - Political': 0.0, 'TownHall - Science & Tech': 0.0, 'Truth or Fiction': 0.0, 'UN News Service': 0.0, 'USA.gov Updates': 0.0, 'VICE News - News': 0.0, 'Voice of Russia': 0.0, 'Washington Post - Fact Checker': 0.0, 'Washington Post - National News': 0.0, 'Washington Post - Politics': 0.0, 'Washington Post - World News': 0.0, 'Washington Times - Culture': 0.0, 'Washington Times - National': 0.0, 'Washington Times - News': 0.0, 'Washington Times - Politics': 0.0, 'Washington Times - Tech': 0.0, 'Wikinews': 0.0, 'Wired': 0.0, 'WTFJHT': 0.0, 'XKCD': 0.0, 'Yahoo News': 0.0, 'Yahoo News - Politics': 0.0, 'Yahoo News - Top Stories': 0.0, 'yam.md Moldova': 0.0, 'Zawya - Exclusive': 0.0, 'Zawya - Latest': 0.0, 'Zawya - Top Markets': 0.0, 'Zawya - Top Regional': 0.0, 'Zehabesha - all': 0.0, 'ZeroHedge - News': 0.0}})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9bc2FN-e5nP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RUN THIS TO MAKE SURE THAT SPACY IS WORKING\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_trf_distilbertbaseuncased_lg')\n",
        "doc = nlp(\"Apple shares rose on the news. Apple pie is delicious.\")\n",
        "print(doc[0].similarity(doc[7]))\n",
        "print(doc._.trf_last_hidden_state.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQJuNlC7hHra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_DATA = [\n",
        "    (\"text1\", {\"cats\": {\"POSITIVE\": 1.0, \"NEGATIVE\": 0.0, \"TESTING\": 0.0}})\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhsoEOcNhLag",
        "colab_type": "code",
        "outputId": "46b55e40-ddc4-47c6-caec-0a3150357821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import spacy\n",
        "import random\n",
        "import torch\n",
        "\n",
        "from spacy.util         import minibatch\n",
        "from spacy_transformers import TransformersLanguage, TransformersWordPiecer, TransformersTok2Vec\n",
        "\n",
        "BATCH_SIZE = 1000\n",
        "ITERATIONS = 2\n",
        "MODEL      = \"distilbert-base-uncased\"\n",
        "\n",
        "is_using_gpu = spacy.prefer_gpu()\n",
        "if is_using_gpu:\n",
        "    print(\"USING GPU\")\n",
        "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
        "\n",
        "print(f\"Number of lables: {len(list_of_sites)}\")\n",
        "print(f\"Number of training data: {len(TRAIN_DATA)}\")\n",
        "\n",
        "nlp = spacy.load(\"en_trf_distilbertbaseuncased_lg\")\n",
        "print(nlp.pipe_names) # [\"sentencizer\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
        "textnews = nlp.create_pipe(\"trf_textcat\", config={\"exclusive_classes\": True})\n",
        "for label in list_of_sites:\n",
        "    textnews.add_label(label)\n",
        "nlp.add_pipe(textnews)\n",
        "optimizer = nlp.resume_training()\n",
        "for i in range(ITERATIONS):\n",
        "    random.shuffle(TRAIN_DATA)\n",
        "    losses = {}\n",
        "    for x, batch in enumerate(minibatch(TRAIN_DATA, size=BATCH_SIZE)):\n",
        "        texts, news = zip(*batch)\n",
        "        nlp.update(texts, news, sgd=optimizer, losses=losses)\n",
        "        print(f\"Batch number: {x}, Losses: {losses}\")\n",
        "    print(f\"Iteration: {i}, Losses: {losses}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "USING GPU\n",
            "Number of lables: 450\n",
            "Number of training data: 240403\n",
            "['sentencizer', 'trf_wordpiecer', 'trf_tok2vec']\n",
            "Batch number: 0, Losses: {'trf_textcat': 9.977775334846228e-07}\n",
            "Batch number: 1, Losses: {'trf_textcat': 1.9948396356994635e-06}\n",
            "Batch number: 2, Losses: {'trf_textcat': 2.9914148171883426e-06}\n",
            "Batch number: 3, Losses: {'trf_textcat': 3.992650817963295e-06}\n",
            "Batch number: 4, Losses: {'trf_textcat': 4.993356014892925e-06}\n",
            "Batch number: 5, Losses: {'trf_textcat': 5.991116836412402e-06}\n",
            "Batch number: 6, Losses: {'trf_textcat': 6.985108484514058e-06}\n",
            "Batch number: 7, Losses: {'trf_textcat': 7.977493510225031e-06}\n",
            "Batch number: 8, Losses: {'trf_textcat': 8.969859663920943e-06}\n",
            "Batch number: 9, Losses: {'trf_textcat': 9.960341685655294e-06}\n",
            "Batch number: 10, Losses: {'trf_textcat': 1.094969775294885e-05}\n",
            "Batch number: 11, Losses: {'trf_textcat': 1.1938822581214481e-05}\n",
            "Batch number: 12, Losses: {'trf_textcat': 1.292797492169484e-05}\n",
            "Batch number: 13, Losses: {'trf_textcat': 1.3916229477217712e-05}\n",
            "Batch number: 14, Losses: {'trf_textcat': 1.4904923659742053e-05}\n",
            "Batch number: 15, Losses: {'trf_textcat': 1.5893121371846064e-05}\n",
            "Batch number: 16, Losses: {'trf_textcat': 1.688143015599053e-05}\n",
            "Batch number: 17, Losses: {'trf_textcat': 1.7871349427878158e-05}\n",
            "Batch number: 18, Losses: {'trf_textcat': 1.885963934000756e-05}\n",
            "Batch number: 19, Losses: {'trf_textcat': 1.9847659700644726e-05}\n",
            "Batch number: 20, Losses: {'trf_textcat': 2.0836345015595725e-05}\n",
            "Batch number: 21, Losses: {'trf_textcat': 2.1825404019182315e-05}\n",
            "Batch number: 22, Losses: {'trf_textcat': 2.2813141072219878e-05}\n",
            "Batch number: 23, Losses: {'trf_textcat': 2.380275236646412e-05}\n",
            "Batch number: 24, Losses: {'trf_textcat': 2.4790078555270156e-05}\n",
            "Batch number: 25, Losses: {'trf_textcat': 2.5778852659641416e-05}\n",
            "Batch number: 26, Losses: {'trf_textcat': 2.6768233510665596e-05}\n",
            "Batch number: 27, Losses: {'trf_textcat': 2.7756861527450383e-05}\n",
            "Batch number: 28, Losses: {'trf_textcat': 2.8744410087711003e-05}\n",
            "Batch number: 29, Losses: {'trf_textcat': 2.9733217957073066e-05}\n",
            "Batch number: 30, Losses: {'trf_textcat': 3.07212997086026e-05}\n",
            "Batch number: 31, Losses: {'trf_textcat': 3.1709222525933e-05}\n",
            "Batch number: 32, Losses: {'trf_textcat': 3.26959208223343e-05}\n",
            "Batch number: 33, Losses: {'trf_textcat': 3.368451484675461e-05}\n",
            "Batch number: 34, Losses: {'trf_textcat': 3.4673191862566455e-05}\n",
            "Batch number: 35, Losses: {'trf_textcat': 3.566022360246279e-05}\n",
            "Batch number: 36, Losses: {'trf_textcat': 3.6650105812441325e-05}\n",
            "Batch number: 37, Losses: {'trf_textcat': 3.7638119465555064e-05}\n",
            "Batch number: 38, Losses: {'trf_textcat': 3.8625962474725384e-05}\n",
            "Batch number: 39, Losses: {'trf_textcat': 3.961344793879107e-05}\n",
            "Batch number: 40, Losses: {'trf_textcat': 4.0600824036118865e-05}\n",
            "Batch number: 41, Losses: {'trf_textcat': 4.1589925444895925e-05}\n",
            "Batch number: 42, Losses: {'trf_textcat': 4.258000763002201e-05}\n",
            "Batch number: 43, Losses: {'trf_textcat': 4.356801014182565e-05}\n",
            "Batch number: 44, Losses: {'trf_textcat': 4.455703492567409e-05}\n",
            "Batch number: 45, Losses: {'trf_textcat': 4.55458215355975e-05}\n",
            "Batch number: 46, Losses: {'trf_textcat': 4.6533397153325495e-05}\n",
            "Batch number: 47, Losses: {'trf_textcat': 4.752178267608542e-05}\n",
            "Batch number: 48, Losses: {'trf_textcat': 4.851002540817717e-05}\n",
            "Batch number: 49, Losses: {'trf_textcat': 4.949834396938968e-05}\n",
            "Batch number: 50, Losses: {'trf_textcat': 5.048672028351575e-05}\n",
            "Batch number: 51, Losses: {'trf_textcat': 5.147490378476505e-05}\n",
            "Batch number: 52, Losses: {'trf_textcat': 5.24633867371449e-05}\n",
            "Batch number: 53, Losses: {'trf_textcat': 5.3450588779924146e-05}\n",
            "Batch number: 54, Losses: {'trf_textcat': 5.443971610930021e-05}\n",
            "Batch number: 55, Losses: {'trf_textcat': 5.542699716443167e-05}\n",
            "Batch number: 56, Losses: {'trf_textcat': 5.641490531616e-05}\n",
            "Batch number: 57, Losses: {'trf_textcat': 5.74037512706127e-05}\n",
            "Batch number: 58, Losses: {'trf_textcat': 5.839201503476943e-05}\n",
            "Batch number: 59, Losses: {'trf_textcat': 5.9379725030339614e-05}\n",
            "Batch number: 60, Losses: {'trf_textcat': 6.036831609890214e-05}\n",
            "Batch number: 61, Losses: {'trf_textcat': 6.13565115372694e-05}\n",
            "Batch number: 62, Losses: {'trf_textcat': 6.234396698800992e-05}\n",
            "Batch number: 63, Losses: {'trf_textcat': 6.333245084988448e-05}\n",
            "Batch number: 64, Losses: {'trf_textcat': 6.432031841541175e-05}\n",
            "Batch number: 65, Losses: {'trf_textcat': 6.530899099743692e-05}\n",
            "Batch number: 66, Losses: {'trf_textcat': 6.629738766150695e-05}\n",
            "Batch number: 67, Losses: {'trf_textcat': 6.728656956056511e-05}\n",
            "Batch number: 68, Losses: {'trf_textcat': 6.827437221090804e-05}\n",
            "Batch number: 69, Losses: {'trf_textcat': 6.926195806045143e-05}\n",
            "Batch number: 70, Losses: {'trf_textcat': 7.025151251127681e-05}\n",
            "Batch number: 71, Losses: {'trf_textcat': 7.123981606582674e-05}\n",
            "Batch number: 72, Losses: {'trf_textcat': 7.22288586985087e-05}\n",
            "Batch number: 73, Losses: {'trf_textcat': 7.321673331261991e-05}\n",
            "Batch number: 74, Losses: {'trf_textcat': 7.420674057811993e-05}\n",
            "Batch number: 75, Losses: {'trf_textcat': 7.519470500483294e-05}\n",
            "Batch number: 76, Losses: {'trf_textcat': 7.61840568657135e-05}\n",
            "Batch number: 77, Losses: {'trf_textcat': 7.71721912542489e-05}\n",
            "Batch number: 78, Losses: {'trf_textcat': 7.816077686584322e-05}\n",
            "Batch number: 79, Losses: {'trf_textcat': 7.914823027022067e-05}\n",
            "Batch number: 80, Losses: {'trf_textcat': 8.01359304887228e-05}\n",
            "Batch number: 81, Losses: {'trf_textcat': 8.112408841043361e-05}\n",
            "Batch number: 82, Losses: {'trf_textcat': 8.211289264181687e-05}\n",
            "Batch number: 83, Losses: {'trf_textcat': 8.310219629947824e-05}\n",
            "Batch number: 84, Losses: {'trf_textcat': 8.409191696046037e-05}\n",
            "Batch number: 85, Losses: {'trf_textcat': 8.50812663202305e-05}\n",
            "Batch number: 86, Losses: {'trf_textcat': 8.607055929132912e-05}\n",
            "Batch number: 87, Losses: {'trf_textcat': 8.705942684628099e-05}\n",
            "Batch number: 88, Losses: {'trf_textcat': 8.804623814739898e-05}\n",
            "Batch number: 89, Losses: {'trf_textcat': 8.903447849206714e-05}\n",
            "Batch number: 90, Losses: {'trf_textcat': 9.002294564197655e-05}\n",
            "Batch number: 91, Losses: {'trf_textcat': 9.101079592710448e-05}\n",
            "Batch number: 92, Losses: {'trf_textcat': 9.199844578233751e-05}\n",
            "Batch number: 93, Losses: {'trf_textcat': 9.29864297631866e-05}\n",
            "Batch number: 94, Losses: {'trf_textcat': 9.397532880939252e-05}\n",
            "Batch number: 95, Losses: {'trf_textcat': 9.496363486505288e-05}\n",
            "Batch number: 96, Losses: {'trf_textcat': 9.59528898647477e-05}\n",
            "Batch number: 97, Losses: {'trf_textcat': 9.694011487226817e-05}\n",
            "Batch number: 98, Losses: {'trf_textcat': 9.792870935143583e-05}\n",
            "Batch number: 99, Losses: {'trf_textcat': 9.891672982575983e-05}\n",
            "Batch number: 100, Losses: {'trf_textcat': 9.990477622068283e-05}\n",
            "Batch number: 101, Losses: {'trf_textcat': 0.00010089268141655339}\n",
            "Batch number: 102, Losses: {'trf_textcat': 0.00010188124838350632}\n",
            "Batch number: 103, Losses: {'trf_textcat': 0.00010286858207564364}\n",
            "Batch number: 104, Losses: {'trf_textcat': 0.00010385668576873286}\n",
            "Batch number: 105, Losses: {'trf_textcat': 0.00010484636629826127}\n",
            "Batch number: 106, Losses: {'trf_textcat': 0.00010583493588001147}\n",
            "Batch number: 107, Losses: {'trf_textcat': 0.00010682221466140618}\n",
            "Batch number: 108, Losses: {'trf_textcat': 0.00010780952777622588}\n",
            "Batch number: 109, Losses: {'trf_textcat': 0.00010879557976295473}\n",
            "Batch number: 110, Losses: {'trf_textcat': 0.00010978437114772532}\n",
            "Batch number: 111, Losses: {'trf_textcat': 0.00011077294630013057}\n",
            "Batch number: 112, Losses: {'trf_textcat': 0.00011176091516063025}\n",
            "Batch number: 113, Losses: {'trf_textcat': 0.0001127491259467206}\n",
            "Batch number: 114, Losses: {'trf_textcat': 0.00011373642337275669}\n",
            "Batch number: 115, Losses: {'trf_textcat': 0.00011472450705696247}\n",
            "Batch number: 116, Losses: {'trf_textcat': 0.00011571270397325861}\n",
            "Batch number: 117, Losses: {'trf_textcat': 0.00011670161393340095}\n",
            "Batch number: 118, Losses: {'trf_textcat': 0.00011769061666200287}\n",
            "Batch number: 119, Losses: {'trf_textcat': 0.00011867767750572966}\n",
            "Batch number: 120, Losses: {'trf_textcat': 0.00011966676788688346}\n",
            "Batch number: 121, Losses: {'trf_textcat': 0.00012065558064477955}\n",
            "Batch number: 122, Losses: {'trf_textcat': 0.00012164448548901419}\n",
            "Batch number: 123, Losses: {'trf_textcat': 0.0001226332205988001}\n",
            "Batch number: 124, Losses: {'trf_textcat': 0.00012362115705855103}\n",
            "Batch number: 125, Losses: {'trf_textcat': 0.00012461107144190464}\n",
            "Batch number: 126, Losses: {'trf_textcat': 0.00012559790570776386}\n",
            "Batch number: 127, Losses: {'trf_textcat': 0.0001265859896193433}\n",
            "Batch number: 128, Losses: {'trf_textcat': 0.00012757425020026858}\n",
            "Batch number: 129, Losses: {'trf_textcat': 0.00012856177170306182}\n",
            "Batch number: 130, Losses: {'trf_textcat': 0.00012955050476648466}\n",
            "Batch number: 131, Losses: {'trf_textcat': 0.00013053883492375462}\n",
            "Batch number: 132, Losses: {'trf_textcat': 0.00013152702661045623}\n",
            "Batch number: 133, Losses: {'trf_textcat': 0.000132516116309489}\n",
            "Batch number: 134, Losses: {'trf_textcat': 0.00013350365418318688}\n",
            "Batch number: 135, Losses: {'trf_textcat': 0.00013449302014123532}\n",
            "Batch number: 136, Losses: {'trf_textcat': 0.00013548118715789315}\n",
            "Batch number: 137, Losses: {'trf_textcat': 0.00013646947195411485}\n",
            "Batch number: 138, Losses: {'trf_textcat': 0.00013745827777711384}\n",
            "Batch number: 139, Losses: {'trf_textcat': 0.00013844742557012069}\n",
            "Batch number: 140, Losses: {'trf_textcat': 0.00013943689384632307}\n",
            "Batch number: 141, Losses: {'trf_textcat': 0.00014042508814782195}\n",
            "Batch number: 142, Losses: {'trf_textcat': 0.0001414127790440034}\n",
            "Batch number: 143, Losses: {'trf_textcat': 0.00014240093855732994}\n",
            "Batch number: 144, Losses: {'trf_textcat': 0.00014338969526761502}\n",
            "Batch number: 145, Losses: {'trf_textcat': 0.00014437746358453296}\n",
            "Batch number: 146, Losses: {'trf_textcat': 0.00014536571859480318}\n",
            "Batch number: 147, Losses: {'trf_textcat': 0.00014635284924224834}\n",
            "Batch number: 148, Losses: {'trf_textcat': 0.00014734165142726852}\n",
            "Batch number: 149, Losses: {'trf_textcat': 0.0001483295976640875}\n",
            "Batch number: 150, Losses: {'trf_textcat': 0.00014931715850252658}\n",
            "Batch number: 151, Losses: {'trf_textcat': 0.00015030535223559127}\n",
            "Batch number: 152, Losses: {'trf_textcat': 0.00015129319115203543}\n",
            "Batch number: 153, Losses: {'trf_textcat': 0.0001522810264305008}\n",
            "Batch number: 154, Losses: {'trf_textcat': 0.00015326783579894254}\n",
            "Batch number: 155, Losses: {'trf_textcat': 0.00015425588276229973}\n",
            "Batch number: 156, Losses: {'trf_textcat': 0.00015524445962000755}\n",
            "Batch number: 157, Losses: {'trf_textcat': 0.00015623260640040826}\n",
            "Batch number: 158, Losses: {'trf_textcat': 0.00015722051261946035}\n",
            "Batch number: 159, Losses: {'trf_textcat': 0.00015820818009615323}\n",
            "Batch number: 160, Losses: {'trf_textcat': 0.00015919668521746644}\n",
            "Batch number: 161, Losses: {'trf_textcat': 0.00016018472592804756}\n",
            "Batch number: 162, Losses: {'trf_textcat': 0.0001611715108538192}\n",
            "Batch number: 163, Losses: {'trf_textcat': 0.00016215948835451854}\n",
            "Batch number: 164, Losses: {'trf_textcat': 0.00016314804929606908}\n",
            "Batch number: 165, Losses: {'trf_textcat': 0.00016413601815656875}\n",
            "Batch number: 166, Losses: {'trf_textcat': 0.00016512473416696594}\n",
            "Batch number: 167, Losses: {'trf_textcat': 0.0001661134230062089}\n",
            "Batch number: 168, Losses: {'trf_textcat': 0.00016710203135517077}\n",
            "Batch number: 169, Losses: {'trf_textcat': 0.00016808903228593408}\n",
            "Batch number: 170, Losses: {'trf_textcat': 0.00016907823430756252}\n",
            "Batch number: 171, Losses: {'trf_textcat': 0.00017006776874950447}\n",
            "Batch number: 172, Losses: {'trf_textcat': 0.00017105583219745313}\n",
            "Batch number: 173, Losses: {'trf_textcat': 0.00017204364394274307}\n",
            "Batch number: 174, Losses: {'trf_textcat': 0.0001730311813616936}\n",
            "Batch number: 175, Losses: {'trf_textcat': 0.00017401879381395702}\n",
            "Batch number: 176, Losses: {'trf_textcat': 0.00017500756177923904}\n",
            "Batch number: 177, Losses: {'trf_textcat': 0.00017599572538529173}\n",
            "Batch number: 178, Losses: {'trf_textcat': 0.00017698454962555843}\n",
            "Batch number: 179, Losses: {'trf_textcat': 0.00017797382656681293}\n",
            "Batch number: 180, Losses: {'trf_textcat': 0.00017896198835387622}\n",
            "Batch number: 181, Losses: {'trf_textcat': 0.00017995027144479536}\n",
            "Batch number: 182, Losses: {'trf_textcat': 0.00018093785843120713}\n",
            "Batch number: 183, Losses: {'trf_textcat': 0.00018192699383234867}\n",
            "Batch number: 184, Losses: {'trf_textcat': 0.00018291473691078863}\n",
            "Batch number: 185, Losses: {'trf_textcat': 0.0001839027455616815}\n",
            "Batch number: 186, Losses: {'trf_textcat': 0.00018489094395590655}\n",
            "Batch number: 187, Losses: {'trf_textcat': 0.00018587907743494725}\n",
            "Batch number: 188, Losses: {'trf_textcat': 0.0001868674868319431}\n",
            "Batch number: 189, Losses: {'trf_textcat': 0.00018785604879667517}\n",
            "Batch number: 190, Losses: {'trf_textcat': 0.00018884511916894553}\n",
            "Batch number: 191, Losses: {'trf_textcat': 0.00018983309064424247}\n",
            "Batch number: 192, Losses: {'trf_textcat': 0.0001908214544528164}\n",
            "Batch number: 193, Losses: {'trf_textcat': 0.0001918098179203298}\n",
            "Batch number: 194, Losses: {'trf_textcat': 0.0001927986065766163}\n",
            "Batch number: 195, Losses: {'trf_textcat': 0.00019378673380288092}\n",
            "Batch number: 196, Losses: {'trf_textcat': 0.0001947747168742353}\n",
            "Batch number: 197, Losses: {'trf_textcat': 0.00019576351905925549}\n",
            "Batch number: 198, Losses: {'trf_textcat': 0.00019675231544624694}\n",
            "Batch number: 199, Losses: {'trf_textcat': 0.00019774079862600047}\n",
            "Batch number: 200, Losses: {'trf_textcat': 0.00019872927657615946}\n",
            "Batch number: 201, Losses: {'trf_textcat': 0.00019971873393842543}\n",
            "Batch number: 202, Losses: {'trf_textcat': 0.0002007074875791659}\n",
            "Batch number: 203, Losses: {'trf_textcat': 0.0002016948474192759}\n",
            "Batch number: 204, Losses: {'trf_textcat': 0.00020268257048883243}\n",
            "Batch number: 205, Losses: {'trf_textcat': 0.00020367001366139448}\n",
            "Batch number: 206, Losses: {'trf_textcat': 0.00020465935369884392}\n",
            "Batch number: 207, Losses: {'trf_textcat': 0.00020564783596910274}\n",
            "Batch number: 208, Losses: {'trf_textcat': 0.0002066356787508994}\n",
            "Batch number: 209, Losses: {'trf_textcat': 0.0002076241241866228}\n",
            "Batch number: 210, Losses: {'trf_textcat': 0.00020861223515566962}\n",
            "Batch number: 211, Losses: {'trf_textcat': 0.00020959981407031592}\n",
            "Batch number: 212, Losses: {'trf_textcat': 0.00021058698314391222}\n",
            "Batch number: 213, Losses: {'trf_textcat': 0.00021157373089408793}\n",
            "Batch number: 214, Losses: {'trf_textcat': 0.00021256207321584952}\n",
            "Batch number: 215, Losses: {'trf_textcat': 0.00021354986029109568}\n",
            "Batch number: 216, Losses: {'trf_textcat': 0.00021453769102208753}\n",
            "Batch number: 217, Losses: {'trf_textcat': 0.00021552611622155382}\n",
            "Batch number: 218, Losses: {'trf_textcat': 0.00021651440772529895}\n",
            "Batch number: 219, Losses: {'trf_textcat': 0.0002175026510258249}\n",
            "Batch number: 220, Losses: {'trf_textcat': 0.0002184903532906901}\n",
            "Batch number: 221, Losses: {'trf_textcat': 0.00021947995014670596}\n",
            "Batch number: 222, Losses: {'trf_textcat': 0.00022046831304578518}\n",
            "Batch number: 223, Losses: {'trf_textcat': 0.00022145539787743473}\n",
            "Batch number: 224, Losses: {'trf_textcat': 0.00022244346689603844}\n",
            "Batch number: 225, Losses: {'trf_textcat': 0.00022343162561355712}\n",
            "Batch number: 226, Losses: {'trf_textcat': 0.00022441950034135516}\n",
            "Batch number: 227, Losses: {'trf_textcat': 0.00022540797704095894}\n",
            "Batch number: 228, Losses: {'trf_textcat': 0.00022639623784925789}\n",
            "Batch number: 229, Losses: {'trf_textcat': 0.00022738406823918922}\n",
            "Batch number: 230, Losses: {'trf_textcat': 0.00022837215908566577}\n",
            "Batch number: 231, Losses: {'trf_textcat': 0.00022936189952815766}\n",
            "Batch number: 232, Losses: {'trf_textcat': 0.0002303501358937865}\n",
            "Batch number: 233, Losses: {'trf_textcat': 0.0002313389513801667}\n",
            "Batch number: 234, Losses: {'trf_textcat': 0.00023232689397900685}\n",
            "Batch number: 235, Losses: {'trf_textcat': 0.00023331460272402182}\n",
            "Batch number: 236, Losses: {'trf_textcat': 0.00023430325700246613}\n",
            "Batch number: 237, Losses: {'trf_textcat': 0.0002352908036300505}\n",
            "Batch number: 238, Losses: {'trf_textcat': 0.000236278733382278}\n",
            "Batch number: 239, Losses: {'trf_textcat': 0.0002372677109860888}\n",
            "Batch number: 240, Losses: {'trf_textcat': 0.00024336898297860898}\n",
            "Iteration: 0, Losses: {'trf_textcat': 0.00024336898297860898}\n",
            "Batch number: 0, Losses: {'trf_textcat': 9.87230578175513e-07}\n",
            "Batch number: 1, Losses: {'trf_textcat': 1.9748877093661577e-06}\n",
            "Batch number: 2, Losses: {'trf_textcat': 2.9631496545334812e-06}\n",
            "Batch number: 3, Losses: {'trf_textcat': 3.9520247128166375e-06}\n",
            "Batch number: 4, Losses: {'trf_textcat': 4.939766085954034e-06}\n",
            "Batch number: 5, Losses: {'trf_textcat': 5.92834373946971e-06}\n",
            "Batch number: 6, Losses: {'trf_textcat': 6.917672862982727e-06}\n",
            "Batch number: 7, Losses: {'trf_textcat': 7.905350116743648e-06}\n",
            "Batch number: 8, Losses: {'trf_textcat': 8.894150937521772e-06}\n",
            "Batch number: 9, Losses: {'trf_textcat': 9.882653216664039e-06}\n",
            "Batch number: 10, Losses: {'trf_textcat': 1.0870372307181242e-05}\n",
            "Batch number: 11, Losses: {'trf_textcat': 1.1857377216983878e-05}\n",
            "Batch number: 12, Losses: {'trf_textcat': 1.284499899156799e-05}\n",
            "Batch number: 13, Losses: {'trf_textcat': 1.3832319154971628e-05}\n",
            "Batch number: 14, Losses: {'trf_textcat': 1.4820106230217789e-05}\n",
            "Batch number: 15, Losses: {'trf_textcat': 1.580868661221757e-05}\n",
            "Batch number: 16, Losses: {'trf_textcat': 1.679642332419462e-05}\n",
            "Batch number: 17, Losses: {'trf_textcat': 1.778444641331589e-05}\n",
            "Batch number: 18, Losses: {'trf_textcat': 1.8771884356283408e-05}\n",
            "Batch number: 19, Losses: {'trf_textcat': 1.976048815777176e-05}\n",
            "Batch number: 20, Losses: {'trf_textcat': 2.074885117053782e-05}\n",
            "Batch number: 21, Losses: {'trf_textcat': 2.1736968619734398e-05}\n",
            "Batch number: 22, Losses: {'trf_textcat': 2.2725148028257536e-05}\n",
            "Batch number: 23, Losses: {'trf_textcat': 2.3713011387371807e-05}\n",
            "Batch number: 24, Losses: {'trf_textcat': 2.4700753670003905e-05}\n",
            "Batch number: 25, Losses: {'trf_textcat': 2.5688243340482586e-05}\n",
            "Batch number: 26, Losses: {'trf_textcat': 2.6675621711547137e-05}\n",
            "Batch number: 27, Losses: {'trf_textcat': 2.7663463811222755e-05}\n",
            "Batch number: 28, Losses: {'trf_textcat': 2.8652337732637534e-05}\n",
            "Batch number: 29, Losses: {'trf_textcat': 2.9641470064234454e-05}\n",
            "Batch number: 30, Losses: {'trf_textcat': 3.062983478230308e-05}\n",
            "Batch number: 31, Losses: {'trf_textcat': 3.161814515806327e-05}\n",
            "Batch number: 32, Losses: {'trf_textcat': 3.260690539264033e-05}\n",
            "Batch number: 33, Losses: {'trf_textcat': 3.359478387210402e-05}\n",
            "Batch number: 34, Losses: {'trf_textcat': 3.4583133924570575e-05}\n",
            "Batch number: 35, Losses: {'trf_textcat': 3.557099876161374e-05}\n",
            "Batch number: 36, Losses: {'trf_textcat': 3.655881573649822e-05}\n",
            "Batch number: 37, Losses: {'trf_textcat': 3.754742158434965e-05}\n",
            "Batch number: 38, Losses: {'trf_textcat': 3.8536152032975224e-05}\n",
            "Batch number: 39, Losses: {'trf_textcat': 3.952359213599266e-05}\n",
            "Batch number: 40, Losses: {'trf_textcat': 4.0512278587812034e-05}\n",
            "Batch number: 41, Losses: {'trf_textcat': 4.150139307057543e-05}\n",
            "Batch number: 42, Losses: {'trf_textcat': 4.248940024353942e-05}\n",
            "Batch number: 43, Losses: {'trf_textcat': 4.34777223290439e-05}\n",
            "Batch number: 44, Losses: {'trf_textcat': 4.4465235646384826e-05}\n",
            "Batch number: 45, Losses: {'trf_textcat': 4.545339925243752e-05}\n",
            "Batch number: 46, Losses: {'trf_textcat': 4.64415606984403e-05}\n",
            "Batch number: 47, Losses: {'trf_textcat': 4.7429608002858004e-05}\n",
            "Batch number: 48, Losses: {'trf_textcat': 4.841782595121913e-05}\n",
            "Batch number: 49, Losses: {'trf_textcat': 4.9406006496610644e-05}\n",
            "Batch number: 50, Losses: {'trf_textcat': 5.0392936714160896e-05}\n",
            "Batch number: 51, Losses: {'trf_textcat': 5.138070207522105e-05}\n",
            "Batch number: 52, Losses: {'trf_textcat': 5.236889887783036e-05}\n",
            "Batch number: 53, Losses: {'trf_textcat': 5.3357204706117045e-05}\n",
            "Batch number: 54, Losses: {'trf_textcat': 5.434609886378894e-05}\n",
            "Batch number: 55, Losses: {'trf_textcat': 5.533402861601644e-05}\n",
            "Batch number: 56, Losses: {'trf_textcat': 5.632319096093852e-05}\n",
            "Batch number: 57, Losses: {'trf_textcat': 5.731046439905185e-05}\n",
            "Batch number: 58, Losses: {'trf_textcat': 5.829879751217959e-05}\n",
            "Batch number: 59, Losses: {'trf_textcat': 5.928681173372752e-05}\n",
            "Batch number: 60, Losses: {'trf_textcat': 6.0275732607806276e-05}\n",
            "Batch number: 61, Losses: {'trf_textcat': 6.126350967861072e-05}\n",
            "Batch number: 62, Losses: {'trf_textcat': 6.22514673978003e-05}\n",
            "Batch number: 63, Losses: {'trf_textcat': 6.323901834548451e-05}\n",
            "Batch number: 64, Losses: {'trf_textcat': 6.422811316042498e-05}\n",
            "Batch number: 65, Losses: {'trf_textcat': 6.521638749745762e-05}\n",
            "Batch number: 66, Losses: {'trf_textcat': 6.620434260184993e-05}\n",
            "Batch number: 67, Losses: {'trf_textcat': 6.719157534007536e-05}\n",
            "Batch number: 68, Losses: {'trf_textcat': 6.817972632688907e-05}\n",
            "Batch number: 69, Losses: {'trf_textcat': 6.91678789053185e-05}\n",
            "Batch number: 70, Losses: {'trf_textcat': 7.015712321845058e-05}\n",
            "Batch number: 71, Losses: {'trf_textcat': 7.114546679076739e-05}\n",
            "Batch number: 72, Losses: {'trf_textcat': 7.213355729618343e-05}\n",
            "Batch number: 73, Losses: {'trf_textcat': 7.312181344332203e-05}\n",
            "Batch number: 74, Losses: {'trf_textcat': 7.410978366806376e-05}\n",
            "Batch number: 75, Losses: {'trf_textcat': 7.509748559186846e-05}\n",
            "Batch number: 76, Losses: {'trf_textcat': 7.608628231992043e-05}\n",
            "Batch number: 77, Losses: {'trf_textcat': 7.707465044859418e-05}\n",
            "Batch number: 78, Losses: {'trf_textcat': 7.806127871390345e-05}\n",
            "Batch number: 79, Losses: {'trf_textcat': 7.904939195668703e-05}\n",
            "Batch number: 80, Losses: {'trf_textcat': 8.003731352346222e-05}\n",
            "Batch number: 81, Losses: {'trf_textcat': 8.102516312646912e-05}\n",
            "Batch number: 82, Losses: {'trf_textcat': 8.201446144084912e-05}\n",
            "Batch number: 83, Losses: {'trf_textcat': 8.300381205117446e-05}\n",
            "Batch number: 84, Losses: {'trf_textcat': 8.399203329645388e-05}\n",
            "Batch number: 85, Losses: {'trf_textcat': 8.498013346525113e-05}\n",
            "Batch number: 86, Losses: {'trf_textcat': 8.596904069690936e-05}\n",
            "Batch number: 87, Losses: {'trf_textcat': 8.69552330868828e-05}\n",
            "Batch number: 88, Losses: {'trf_textcat': 8.79434633134224e-05}\n",
            "Batch number: 89, Losses: {'trf_textcat': 8.893284007172042e-05}\n",
            "Batch number: 90, Losses: {'trf_textcat': 8.99214144283178e-05}\n",
            "Batch number: 91, Losses: {'trf_textcat': 9.090934372579795e-05}\n",
            "Batch number: 92, Losses: {'trf_textcat': 9.189636568862625e-05}\n",
            "Batch number: 93, Losses: {'trf_textcat': 9.288465776080557e-05}\n",
            "Batch number: 94, Losses: {'trf_textcat': 9.387313718889345e-05}\n",
            "Batch number: 95, Losses: {'trf_textcat': 9.486223484600487e-05}\n",
            "Batch number: 96, Losses: {'trf_textcat': 9.585077896190342e-05}\n",
            "Batch number: 97, Losses: {'trf_textcat': 9.683823486739129e-05}\n",
            "Batch number: 98, Losses: {'trf_textcat': 9.78275742227197e-05}\n",
            "Batch number: 99, Losses: {'trf_textcat': 9.881626669994148e-05}\n",
            "Batch number: 100, Losses: {'trf_textcat': 9.980540096421464e-05}\n",
            "Batch number: 101, Losses: {'trf_textcat': 0.00010079444041366514}\n",
            "Batch number: 102, Losses: {'trf_textcat': 0.00010178285003803467}\n",
            "Batch number: 103, Losses: {'trf_textcat': 0.00010277170201788977}\n",
            "Batch number: 104, Losses: {'trf_textcat': 0.00010375977569765382}\n",
            "Batch number: 105, Losses: {'trf_textcat': 0.0001047480700435699}\n",
            "Batch number: 106, Losses: {'trf_textcat': 0.00010573625013421406}\n",
            "Batch number: 107, Losses: {'trf_textcat': 0.00010672394239463756}\n",
            "Batch number: 108, Losses: {'trf_textcat': 0.00010771186816782574}\n",
            "Batch number: 109, Losses: {'trf_textcat': 0.00010870049800359993}\n",
            "Batch number: 110, Losses: {'trf_textcat': 0.00010968916558340425}\n",
            "Batch number: 111, Losses: {'trf_textcat': 0.00011067647608342668}\n",
            "Batch number: 112, Losses: {'trf_textcat': 0.00011166503918502713}\n",
            "Batch number: 113, Losses: {'trf_textcat': 0.00011265384364378406}\n",
            "Batch number: 114, Losses: {'trf_textcat': 0.00011364086049070465}\n",
            "Batch number: 115, Losses: {'trf_textcat': 0.00011462872782885825}\n",
            "Batch number: 116, Losses: {'trf_textcat': 0.00011561693088424363}\n",
            "Batch number: 117, Losses: {'trf_textcat': 0.00011660533448321075}\n",
            "Batch number: 118, Losses: {'trf_textcat': 0.00011759405504108145}\n",
            "Batch number: 119, Losses: {'trf_textcat': 0.00011858304469569703}\n",
            "Batch number: 120, Losses: {'trf_textcat': 0.00011957091930980823}\n",
            "Batch number: 121, Losses: {'trf_textcat': 0.00012055964828050492}\n",
            "Batch number: 122, Losses: {'trf_textcat': 0.00012154721287060966}\n",
            "Batch number: 123, Losses: {'trf_textcat': 0.00012253525972028}\n",
            "Batch number: 124, Losses: {'trf_textcat': 0.00012352348051081208}\n",
            "Batch number: 125, Losses: {'trf_textcat': 0.0001245120414523626}\n",
            "Batch number: 126, Losses: {'trf_textcat': 0.0001255002625839552}\n",
            "Batch number: 127, Losses: {'trf_textcat': 0.0001264886682292854}\n",
            "Batch number: 128, Losses: {'trf_textcat': 0.00012747699111059774}\n",
            "Batch number: 129, Losses: {'trf_textcat': 0.0001284664572267502}\n",
            "Batch number: 130, Losses: {'trf_textcat': 0.00012945420439791633}\n",
            "Batch number: 131, Losses: {'trf_textcat': 0.00013044147294749564}\n",
            "Batch number: 132, Losses: {'trf_textcat': 0.00013143046112418233}\n",
            "Batch number: 133, Losses: {'trf_textcat': 0.0001324184139548379}\n",
            "Batch number: 134, Losses: {'trf_textcat': 0.0001334066240588072}\n",
            "Batch number: 135, Losses: {'trf_textcat': 0.00013439525741887337}\n",
            "Batch number: 136, Losses: {'trf_textcat': 0.00013538288544623356}\n",
            "Batch number: 137, Losses: {'trf_textcat': 0.00013637095298690838}\n",
            "Batch number: 138, Losses: {'trf_textcat': 0.00013735860966335167}\n",
            "Batch number: 139, Losses: {'trf_textcat': 0.00013834624076025648}\n",
            "Batch number: 140, Losses: {'trf_textcat': 0.00013933435161561647}\n",
            "Batch number: 141, Losses: {'trf_textcat': 0.00014032238505023997}\n",
            "Batch number: 142, Losses: {'trf_textcat': 0.00014131048828858184}\n",
            "Batch number: 143, Losses: {'trf_textcat': 0.00014229952148525626}\n",
            "Batch number: 144, Losses: {'trf_textcat': 0.00014328782333450363}\n",
            "Batch number: 145, Losses: {'trf_textcat': 0.00014427486041768134}\n",
            "Batch number: 146, Losses: {'trf_textcat': 0.00014526320671848225}\n",
            "Batch number: 147, Losses: {'trf_textcat': 0.00014625245069055381}\n",
            "Batch number: 148, Losses: {'trf_textcat': 0.00014724051072789734}\n",
            "Batch number: 149, Losses: {'trf_textcat': 0.00014822748050846712}\n",
            "Batch number: 150, Losses: {'trf_textcat': 0.00014921582442184445}\n",
            "Batch number: 151, Losses: {'trf_textcat': 0.00015020387741060404}\n",
            "Batch number: 152, Losses: {'trf_textcat': 0.00015119266652163788}\n",
            "Batch number: 153, Losses: {'trf_textcat': 0.0001521809164160004}\n",
            "Batch number: 154, Losses: {'trf_textcat': 0.00015316854467073426}\n",
            "Batch number: 155, Losses: {'trf_textcat': 0.00015415780944749713}\n",
            "Batch number: 156, Losses: {'trf_textcat': 0.00015514518975123792}\n",
            "Batch number: 157, Losses: {'trf_textcat': 0.0001561347839924565}\n",
            "Batch number: 158, Losses: {'trf_textcat': 0.00015712316167082463}\n",
            "Batch number: 159, Losses: {'trf_textcat': 0.00015811112189112464}\n",
            "Batch number: 160, Losses: {'trf_textcat': 0.00015909897877008916}\n",
            "Batch number: 161, Losses: {'trf_textcat': 0.00016008656018584588}\n",
            "Batch number: 162, Losses: {'trf_textcat': 0.00016107451415336982}\n",
            "Batch number: 163, Losses: {'trf_textcat': 0.00016206236477955827}\n",
            "Batch number: 164, Losses: {'trf_textcat': 0.000163049614116062}\n",
            "Batch number: 165, Losses: {'trf_textcat': 0.0001640364628201496}\n",
            "Batch number: 166, Losses: {'trf_textcat': 0.00016502437233612}\n",
            "Batch number: 167, Losses: {'trf_textcat': 0.00016601240895397495}\n",
            "Batch number: 168, Losses: {'trf_textcat': 0.00016700151013537834}\n",
            "Batch number: 169, Losses: {'trf_textcat': 0.00016798953367924696}\n",
            "Batch number: 170, Losses: {'trf_textcat': 0.00016897789294034737}\n",
            "Batch number: 171, Losses: {'trf_textcat': 0.00016996664862745092}\n",
            "Batch number: 172, Losses: {'trf_textcat': 0.00017095486225571221}\n",
            "Batch number: 173, Losses: {'trf_textcat': 0.00017194368172113172}\n",
            "Batch number: 174, Losses: {'trf_textcat': 0.00017293098881054902}\n",
            "Batch number: 175, Losses: {'trf_textcat': 0.000173918633095127}\n",
            "Batch number: 176, Losses: {'trf_textcat': 0.00017490712514245388}\n",
            "Batch number: 177, Losses: {'trf_textcat': 0.0001758962209805759}\n",
            "Batch number: 178, Losses: {'trf_textcat': 0.0001768854687043131}\n",
            "Batch number: 179, Losses: {'trf_textcat': 0.0001778724933956255}\n",
            "Batch number: 180, Losses: {'trf_textcat': 0.00017886191676552698}\n",
            "Batch number: 181, Losses: {'trf_textcat': 0.0001798500876475373}\n",
            "Batch number: 182, Losses: {'trf_textcat': 0.00018083866791585024}\n",
            "Batch number: 183, Losses: {'trf_textcat': 0.0001818266919144662}\n",
            "Batch number: 184, Losses: {'trf_textcat': 0.00018281465384006879}\n",
            "Batch number: 185, Losses: {'trf_textcat': 0.0001838033088006341}\n",
            "Batch number: 186, Losses: {'trf_textcat': 0.00018479110906355345}\n",
            "Batch number: 187, Losses: {'trf_textcat': 0.00018577774471850717}\n",
            "Batch number: 188, Losses: {'trf_textcat': 0.00018676552986107708}\n",
            "Batch number: 189, Losses: {'trf_textcat': 0.00018775358159928146}\n",
            "Batch number: 190, Losses: {'trf_textcat': 0.000188742263731001}\n",
            "Batch number: 191, Losses: {'trf_textcat': 0.0001897298579933704}\n",
            "Batch number: 192, Losses: {'trf_textcat': 0.00019071869428444188}\n",
            "Batch number: 193, Losses: {'trf_textcat': 0.00019170772191046126}\n",
            "Batch number: 194, Losses: {'trf_textcat': 0.0001926963147980132}\n",
            "Batch number: 195, Losses: {'trf_textcat': 0.0001936848015020587}\n",
            "Batch number: 196, Losses: {'trf_textcat': 0.00019467312210963428}\n",
            "Batch number: 197, Losses: {'trf_textcat': 0.00019566160790418508}\n",
            "Batch number: 198, Losses: {'trf_textcat': 0.0001966497809462453}\n",
            "Batch number: 199, Losses: {'trf_textcat': 0.0001976376962602444}\n",
            "Batch number: 200, Losses: {'trf_textcat': 0.00019862487590671662}\n",
            "Batch number: 201, Losses: {'trf_textcat': 0.00019961276586855092}\n",
            "Batch number: 202, Losses: {'trf_textcat': 0.00020060158510659676}\n",
            "Batch number: 203, Losses: {'trf_textcat': 0.00020159013718057395}\n",
            "Batch number: 204, Losses: {'trf_textcat': 0.00020257863104689022}\n",
            "Batch number: 205, Losses: {'trf_textcat': 0.00020356661934783915}\n",
            "Batch number: 206, Losses: {'trf_textcat': 0.0002045572342694868}\n",
            "Batch number: 207, Losses: {'trf_textcat': 0.0002055466163710662}\n",
            "Batch number: 208, Losses: {'trf_textcat': 0.0002065349376607628}\n",
            "Batch number: 209, Losses: {'trf_textcat': 0.0002075234795029246}\n",
            "Batch number: 210, Losses: {'trf_textcat': 0.0002085120481751801}\n",
            "Batch number: 211, Losses: {'trf_textcat': 0.00020950066107161547}\n",
            "Batch number: 212, Losses: {'trf_textcat': 0.00021048855796834687}\n",
            "Batch number: 213, Losses: {'trf_textcat': 0.00021147697714241076}\n",
            "Batch number: 214, Losses: {'trf_textcat': 0.00021246464609703253}\n",
            "Batch number: 215, Losses: {'trf_textcat': 0.00021345207551348722}\n",
            "Batch number: 216, Losses: {'trf_textcat': 0.00021444043852625327}\n",
            "Batch number: 217, Losses: {'trf_textcat': 0.00021542821366438147}\n",
            "Batch number: 218, Losses: {'trf_textcat': 0.00021641737248501158}\n",
            "Batch number: 219, Losses: {'trf_textcat': 0.00021740573890838277}\n",
            "Batch number: 220, Losses: {'trf_textcat': 0.00021839384430677455}\n",
            "Batch number: 221, Losses: {'trf_textcat': 0.00021938269878774008}\n",
            "Batch number: 222, Losses: {'trf_textcat': 0.00022036971495253965}\n",
            "Batch number: 223, Losses: {'trf_textcat': 0.00022135790891297802}\n",
            "Batch number: 224, Losses: {'trf_textcat': 0.00022234775849483412}\n",
            "Batch number: 225, Losses: {'trf_textcat': 0.00022333588822220918}\n",
            "Batch number: 226, Losses: {'trf_textcat': 0.00022432406865391386}\n",
            "Batch number: 227, Losses: {'trf_textcat': 0.00022531282786530937}\n",
            "Batch number: 228, Losses: {'trf_textcat': 0.00022630164539805264}\n",
            "Batch number: 229, Losses: {'trf_textcat': 0.00022728909391389607}\n",
            "Batch number: 230, Losses: {'trf_textcat': 0.00022827752934517775}\n",
            "Batch number: 231, Losses: {'trf_textcat': 0.00022926647295662406}\n",
            "Batch number: 232, Losses: {'trf_textcat': 0.00023025491236694506}\n",
            "Batch number: 233, Losses: {'trf_textcat': 0.00023124299298160622}\n",
            "Batch number: 234, Losses: {'trf_textcat': 0.00023223050573051296}\n",
            "Batch number: 235, Losses: {'trf_textcat': 0.0002332199304646565}\n",
            "Batch number: 236, Losses: {'trf_textcat': 0.0002342074865282484}\n",
            "Batch number: 237, Losses: {'trf_textcat': 0.0002351957326709453}\n",
            "Batch number: 238, Losses: {'trf_textcat': 0.00023618390571300552}\n",
            "Batch number: 239, Losses: {'trf_textcat': 0.00023717299552572513}\n",
            "Batch number: 240, Losses: {'trf_textcat': 0.0002432681252457769}\n",
            "Iteration: 1, Losses: {'trf_textcat': 0.0002432681252457769}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yf9OvL_hea-",
        "colab_type": "code",
        "outputId": "c328b69c-ed50-46ae-b58d-640389fabe00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "a = nlp(\"Parliament passes Zainab Alert Bill for recovery of missing children - Samaa News\")\n",
        "a.cats\n",
        "for key, value in sorted(a.cats.items(), key=lambda item: item[1]):\n",
        "    print(\"%s: %s\" % (key, value))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c890f14a3eb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Parliament passes Zainab Alert Bill for recovery of missing children - Samaa News\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nlp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63Y6ESVLJrZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy_transformers import TransformersLanguage, TransformersWordPiecer, TransformersTok2Vec\n",
        "\n",
        "name = \"bert-base-uncased\"\n",
        "nlp = TransformersLanguage(trf_name=name, meta={\"lang\": \"en\"})\n",
        "nlp.add_pipe(nlp.create_pipe(\"sentencizer\"))\n",
        "nlp.add_pipe(TransformersWordPiecer.from_pretrained(nlp.vocab, name))\n",
        "nlp.add_pipe(TransformersTok2Vec.from_pretrained(nlp.vocab, name))\n",
        "print(nlp.pipe_names)  # ['sentencizer', 'trf_wordpiecer', 'trf_tok2vec']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW37K6y5Kbrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "textnews = nlp.create_pipe(\"trf_textcat\", config={\"exclusive_classes\": True})\n",
        "for label in list_of_sites:\n",
        "    textnews.add_label(label)\n",
        "nlp.add_pipe(textnews)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}